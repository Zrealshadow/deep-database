{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lingze/embedding_fusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from model.base import CompositeModel, FeatureEncodingPart, NodeRepresentationPart\n",
    "from relbench.modeling.nn import HeteroTemporalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import relbench\n",
    "from relbench.base import Table, Database, Dataset, EntityTask\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "from relbench.base import BaseTask\n",
    "from torch_geometric.seed import seed_everything\n",
    "from relbench.modeling.utils import get_stype_proposal\n",
    "from relbench.modeling.graph import make_pkey_fkey_graph\n",
    "from relbench.modeling.graph import get_node_train_table_input\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch_geometric\n",
    "import torch_frame\n",
    "\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "from typing import List, Optional\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from torch.nn import L1Loss, BCEWithLogitsLoss\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/rel-trial/db...\n",
      "Done in 7.85 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(name=\"rel-trial\", download=True)\n",
    "db = dataset.get_db()\n",
    "task_a = get_task(\"rel-trial\", \"study-outcome\", download = True)\n",
    "task_b = get_task(\"rel-trial\", \"site-success\", download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "col_to_stype_dict = get_stype_proposal(db)\n",
    "\n",
    "class GloveTextEmbedding:\n",
    "    def __init__(self, device: Optional[torch.device\n",
    "                                       ] = None):\n",
    "        self.model = SentenceTransformer(\n",
    "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def __call__(self, sentences: List[str]) -> Tensor:\n",
    "        return torch.from_numpy(self.model.encode(sentences))\n",
    "\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=GloveTextEmbedding(device=device), batch_size=256\n",
    ")\n",
    "\n",
    "\n",
    "root_dir = \"/home/lingze/embedding_fusion/data\"\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    db,\n",
    "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
    "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
    "    cache_dir=os.path.join(\n",
    "        root_dir, f\"rel-trial_materialized_cache\"\n",
    "    ),  # store materialized graph for convenience\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_loader_dict(task: BaseTask) -> dict:\n",
    "    loader_dict = {}\n",
    "    for split, table in [\n",
    "        (\"train\", task.get_table(\"train\")),\n",
    "        (\"val\",task.get_table(\"val\")),\n",
    "        (\"test\", task.get_table(\"test\")),\n",
    "    ]:\n",
    "        table_input = get_node_train_table_input(\n",
    "            table=table,\n",
    "            task=task,\n",
    "        )\n",
    "        loader_dict[split] = NeighborLoader(\n",
    "            data,\n",
    "            num_neighbors=[\n",
    "                128 for i in range(2)\n",
    "            ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
    "            time_attr=\"time\",\n",
    "            input_nodes=table_input.nodes,\n",
    "            input_time=table_input.time,\n",
    "            transform=table_input.transform,\n",
    "            batch_size=512,\n",
    "            temporal_strategy=\"uniform\",\n",
    "            shuffle=split == \"train\",\n",
    "            num_workers=0,\n",
    "            persistent_workers=False,\n",
    "        )\n",
    "    return loader_dict\n",
    "\n",
    "taska_loader_dict = generate_loader_dict(task_a)\n",
    "taskb_loader_dict = generate_loader_dict(task_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 128\n",
    "temporal_encoder = HeteroTemporalEncoder(\n",
    "    node_types=[\n",
    "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
    "            ],\n",
    "            channels=channels,\n",
    ")\n",
    "\n",
    "feat_encoder = FeatureEncodingPart(\n",
    "    data=data,\n",
    "    node_to_col_stats=col_stats_dict,\n",
    "    channels=channels\n",
    ")\n",
    "\n",
    "task_a_node_encoder = NodeRepresentationPart(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    num_layers=1,\n",
    "    normalization=\"layer_norm\",\n",
    "    dropout_prob=0.2\n",
    ")\n",
    "\n",
    "task_b_node_encoder = NodeRepresentationPart(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    num_layers=1,\n",
    "    normalization=\"layer_norm\",\n",
    "    dropout_prob=0.3\n",
    ")\n",
    "\n",
    "task_a_model =  CompositeModel(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    out_channels=1,\n",
    "    dropout=0.2,\n",
    "    aggr=\"mean\",\n",
    "    norm=\"layer_norm\",\n",
    "    num_layer=2,\n",
    "    feature_encoder=feat_encoder,\n",
    "    node_encoder=task_a_node_encoder,\n",
    "    temporal_encoder=temporal_encoder\n",
    ")\n",
    "\n",
    "task_b_model =  CompositeModel(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    out_channels=1,\n",
    "    dropout=0.3,\n",
    "    aggr=\"mean\",\n",
    "    norm=\"layer_norm\",\n",
    "    num_layer=2,\n",
    "    feature_encoder=feat_encoder,\n",
    "    node_encoder=task_b_node_encoder,\n",
    "    temporal_encoder=temporal_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid(loader: NeighborLoader, model: torch.nn.Module, task: BaseTask)-> np.ndarray:\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    pred_hat_list = []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(\n",
    "            batch,\n",
    "            task.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "        pred_list.append(pred.detach().cpu())\n",
    "        pred_hat_list.append(batch[task.entity_table].y.detach().cpu())\n",
    "    return torch.cat(pred_list, dim=0), torch.cat(pred_hat_list, dim=0)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader: NeighborLoader, model: torch.nn.Module, task: BaseTask)-> np.ndarray:\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        pred = model(\n",
    "            batch,\n",
    "            task.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "        pred_list.append(pred.detach().cpu())\n",
    "    return torch.cat(pred_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompositeModel(\n",
       "  (gnn): HeteroGraphSAGE(\n",
       "    (convs): ModuleList(\n",
       "      (0-1): 2 x HeteroConv(num_relations=30)\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0-1): 2 x ModuleDict(\n",
       "        (interventions): LayerNorm(128, affine=True, mode=node)\n",
       "        (interventions_studies): LayerNorm(128, affine=True, mode=node)\n",
       "        (facilities_studies): LayerNorm(128, affine=True, mode=node)\n",
       "        (sponsors): LayerNorm(128, affine=True, mode=node)\n",
       "        (eligibilities): LayerNorm(128, affine=True, mode=node)\n",
       "        (reported_event_totals): LayerNorm(128, affine=True, mode=node)\n",
       "        (designs): LayerNorm(128, affine=True, mode=node)\n",
       "        (conditions_studies): LayerNorm(128, affine=True, mode=node)\n",
       "        (drop_withdrawals): LayerNorm(128, affine=True, mode=node)\n",
       "        (studies): LayerNorm(128, affine=True, mode=node)\n",
       "        (outcome_analyses): LayerNorm(128, affine=True, mode=node)\n",
       "        (sponsors_studies): LayerNorm(128, affine=True, mode=node)\n",
       "        (outcomes): LayerNorm(128, affine=True, mode=node)\n",
       "        (conditions): LayerNorm(128, affine=True, mode=node)\n",
       "        (facilities): LayerNorm(128, affine=True, mode=node)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (head): MLP(128, 1)\n",
       "  (feature_encoder): FeatureEncodingPart(\n",
       "    (encoders): ModuleDict(\n",
       "      (interventions): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (embedding): LinearEmbeddingEncoder(\n",
       "            (weight_list): ParameterList(  (0): Parameter containing: [torch.float32 of size 300x128 (cuda:0)])\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (interventions_studies): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (timestamp): TimestampEncoder(\n",
       "            (positional_encoding): PositionalEncoding()\n",
       "            (cyclic_encoding): CyclicEncoding()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (facilities_studies): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (timestamp): TimestampEncoder(\n",
       "            (positional_encoding): PositionalEncoding()\n",
       "            (cyclic_encoding): CyclicEncoding()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (sponsors): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (embedding): LinearEmbeddingEncoder(\n",
       "            (weight_list): ParameterList(\n",
       "                (0): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (1): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (eligibilities): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (categorical): EmbeddingEncoder(\n",
       "            (emb): Embedding(15, 128, padding_idx=0)\n",
       "          )\n",
       "          (timestamp): TimestampEncoder(\n",
       "            (positional_encoding): PositionalEncoding()\n",
       "            (cyclic_encoding): CyclicEncoding()\n",
       "          )\n",
       "          (embedding): LinearEmbeddingEncoder(\n",
       "            (weight_list): ParameterList(\n",
       "                (0): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (1): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (2): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (3): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (4): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (reported_event_totals): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (categorical): EmbeddingEncoder(\n",
       "            (emb): Embedding(7, 128, padding_idx=0)\n",
       "          )\n",
       "          (numerical): LinearEncoder()\n",
       "          (timestamp): TimestampEncoder(\n",
       "            (positional_encoding): PositionalEncoding()\n",
       "            (cyclic_encoding): CyclicEncoding()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (designs): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (categorical): EmbeddingEncoder(\n",
       "            (emb): Embedding(21, 128, padding_idx=0)\n",
       "          )\n",
       "          (timestamp): TimestampEncoder(\n",
       "            (positional_encoding): PositionalEncoding()\n",
       "            (cyclic_encoding): CyclicEncoding()\n",
       "          )\n",
       "          (embedding): LinearEmbeddingEncoder(\n",
       "            (weight_list): ParameterList(\n",
       "                (0): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (1): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (2): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (3): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conditions_studies): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (timestamp): TimestampEncoder(\n",
       "            (positional_encoding): PositionalEncoding()\n",
       "            (cyclic_encoding): CyclicEncoding()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (drop_withdrawals): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (numerical): LinearEncoder()\n",
       "          (timestamp): TimestampEncoder(\n",
       "            (positional_encoding): PositionalEncoding()\n",
       "            (cyclic_encoding): CyclicEncoding()\n",
       "          )\n",
       "          (embedding): LinearEmbeddingEncoder(\n",
       "            (weight_list): ParameterList(\n",
       "                (0): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (1): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (studies): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (timestamp): TimestampEncoder(\n",
       "            (positional_encoding): PositionalEncoding()\n",
       "            (cyclic_encoding): CyclicEncoding()\n",
       "          )\n",
       "          (categorical): EmbeddingEncoder(\n",
       "            (emb): Embedding(27, 128, padding_idx=0)\n",
       "          )\n",
       "          (numerical): LinearEncoder()\n",
       "          (embedding): LinearEmbeddingEncoder(\n",
       "            (weight_list): ParameterList(\n",
       "                (0): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (1): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (2): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (3): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (4): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (5): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (6): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (7): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (8): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (9): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (10): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (outcome_analyses): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (numerical): LinearEncoder()\n",
       "          (categorical): EmbeddingEncoder(\n",
       "            (emb): Embedding(16, 128, padding_idx=0)\n",
       "          )\n",
       "          (timestamp): TimestampEncoder(\n",
       "            (positional_encoding): PositionalEncoding()\n",
       "            (cyclic_encoding): CyclicEncoding()\n",
       "          )\n",
       "          (embedding): LinearEmbeddingEncoder(\n",
       "            (weight_list): ParameterList(\n",
       "                (0): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (1): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (2): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (3): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (4): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (5): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (6): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (7): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (8): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (sponsors_studies): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (categorical): EmbeddingEncoder(\n",
       "            (emb): Embedding(3, 128, padding_idx=0)\n",
       "          )\n",
       "          (timestamp): TimestampEncoder(\n",
       "            (positional_encoding): PositionalEncoding()\n",
       "            (cyclic_encoding): CyclicEncoding()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (outcomes): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (categorical): EmbeddingEncoder(\n",
       "            (emb): Embedding(14, 128, padding_idx=0)\n",
       "          )\n",
       "          (timestamp): TimestampEncoder(\n",
       "            (positional_encoding): PositionalEncoding()\n",
       "            (cyclic_encoding): CyclicEncoding()\n",
       "          )\n",
       "          (embedding): LinearEmbeddingEncoder(\n",
       "            (weight_list): ParameterList(\n",
       "                (0): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (1): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (2): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (3): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (4): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (5): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (6): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (conditions): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (embedding): LinearEmbeddingEncoder(\n",
       "            (weight_list): ParameterList(  (0): Parameter containing: [torch.float32 of size 300x128 (cuda:0)])\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (facilities): StypeWiseFeatureEncoder(\n",
       "        (encoder_dict): ModuleDict(\n",
       "          (embedding): LinearEmbeddingEncoder(\n",
       "            (weight_list): ParameterList(\n",
       "                (0): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (1): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (2): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (3): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "                (4): Parameter containing: [torch.float32 of size 300x128 (cuda:0)]\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (node_encoder): NodeRepresentationPart(\n",
       "    (mappers): ModuleDict(\n",
       "      (interventions): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (interventions_studies): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (facilities_studies): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (sponsors): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (shortcut): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (eligibilities): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=1664, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (shortcut): Linear(in_features=1664, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (reported_event_totals): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=640, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (shortcut): Linear(in_features=640, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (designs): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=1664, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (shortcut): Linear(in_features=1664, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (conditions_studies): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (drop_withdrawals): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (shortcut): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (studies): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (shortcut): Linear(in_features=3072, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (outcome_analyses): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=2432, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (shortcut): Linear(in_features=2432, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (sponsors_studies): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (shortcut): Linear(in_features=256, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (outcomes): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=1280, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (shortcut): Linear(in_features=1280, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (conditions): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (facilities): Sequential(\n",
       "        (0): FCResidualBlock(\n",
       "          (lin1): Linear(in_features=640, out_features=128, bias=True)\n",
       "          (lin2): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (shortcut): Linear(in_features=640, out_features=128, bias=True)\n",
       "        )\n",
       "        (1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (temporal_encoder): HeteroTemporalEncoder(\n",
       "    (encoder_dict): ModuleDict(\n",
       "      (interventions_studies): PositionalEncoding(128)\n",
       "      (facilities_studies): PositionalEncoding(128)\n",
       "      (eligibilities): PositionalEncoding(128)\n",
       "      (reported_event_totals): PositionalEncoding(128)\n",
       "      (designs): PositionalEncoding(128)\n",
       "      (conditions_studies): PositionalEncoding(128)\n",
       "      (drop_withdrawals): PositionalEncoding(128)\n",
       "      (studies): PositionalEncoding(128)\n",
       "      (outcome_analyses): PositionalEncoding(128)\n",
       "      (sponsors_studies): PositionalEncoding(128)\n",
       "      (outcomes): PositionalEncoding(128)\n",
       "    )\n",
       "    (lin_dict): ModuleDict(\n",
       "      (interventions_studies): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (facilities_studies): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (eligibilities): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (reported_event_totals): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (designs): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (conditions_studies): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (drop_withdrawals): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (studies): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (outcome_analyses): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (sponsors_studies): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (outcomes): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"task_a_model.pth\")\n",
    "task_a_model.load_state_dict(state_dict)\n",
    "task_a_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auroc': 0.6789013596793916,\n",
       " 'accuracy': 0.5878787878787879,\n",
       " 'precision': 0.5868772782503038,\n",
       " 'recall': 1.0,\n",
       " 'f1score': 0.7396630934150077}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test task A\n",
    "test_logits = test(taska_loader_dict[\"test\"], task_a_model, task_a)\n",
    "test_logits =  torch.sigmoid(test_logits).numpy()\n",
    "\n",
    "test_pred = (test_logits > 0.5).astype(int)\n",
    "test_pred_hat = task_a.get_table(\"test\", mask_input_cols = False).df[task_a.target_col].to_numpy()\n",
    "test_metrics = {\n",
    "    \"auroc\": roc_auc_score(test_pred_hat, test_logits),\n",
    "    \"accuracy\": accuracy_score(test_pred_hat, test_pred),\n",
    "    \"precision\": precision_score(test_pred_hat, test_pred),\n",
    "    \"recall\": recall_score(test_pred_hat, test_pred),\n",
    "    \"f1score\": f1_score(test_pred_hat, test_pred),\n",
    "}\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transfer to next task, we freeze the feat_encoder and temporal_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in feat_encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in temporal_encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the model is frozen in task_b_model\n",
    "# for name, param in task_b_model.named_parameters():\n",
    "#     if not param.requires_grad:\n",
    "#         print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train task b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(task_b_model.parameters(), lr=0.002)\n",
    "epochs = 20\n",
    "loss_fn = L1Loss()\n",
    "tune_metric = \"mae\"\n",
    "higher_is_better = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/296 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:02<00:32,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 0.5536862790584565, Val metrics: {'mae': 0.4670303391773532, 'r2': -0.38079538254706535, 'rmse': 0.5613250623192587}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:02<00:31,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 0.45024473965168, Val metrics: {'mae': 0.4661111583558287, 'r2': -0.26958255503306106, 'rmse': 0.538245296443496}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:02<00:33,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 0.4451788246631622, Val metrics: {'mae': 0.4669315650630681, 'r2': -0.48348847423170827, 'rmse': 0.5818243037099271}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:02<00:32,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 0.41880103051662443, Val metrics: {'mae': 0.41400271050683846, 'r2': -0.1293648983073823, 'rmse': 0.5076529484174325}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:27, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 0.3810374766588211, Val metrics: {'mae': 0.42254258938368433, 'r2': -0.3294033846577986, 'rmse': 0.5507799981981856}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:02<00:32,  8.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train loss: 0.3579500004649162, Val metrics: {'mae': 0.41120197855205604, 'r2': -0.30060448276381346, 'rmse': 0.5447815531243743}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:27, 10.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train loss: 0.35562915056943895, Val metrics: {'mae': 0.42772684085532253, 'r2': -0.4230109835497484, 'rmse': 0.5698412661589188}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:27, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train loss: 0.3374470114707947, Val metrics: {'mae': 0.44092946729540966, 'r2': -0.5681434475730074, 'rmse': 0.5981948421486004}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:27, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train loss: 0.32877634167671205, Val metrics: {'mae': 0.43324444231886056, 'r2': -0.46738179516942546, 'rmse': 0.5786571631618113}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:02<00:28,  9.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.32383287996053695, Val metrics: {'mae': 0.43045193042991653, 'r2': -0.4798654928277708, 'rmse': 0.5811134025983531}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:26, 10.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 0.32107689082622526, Val metrics: {'mae': 0.44113570277508013, 'r2': -0.5535773375700734, 'rmse': 0.5954101158791022}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:27, 10.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 0.31160512268543245, Val metrics: {'mae': 0.453359223537947, 'r2': -0.6399061731582747, 'rmse': 0.6117292833285612}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:02<00:31,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 0.3099339172244072, Val metrics: {'mae': 0.4528615220232609, 'r2': -0.6003115625508668, 'rmse': 0.6042992312488685}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:02<00:31,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 0.29516699761152265, Val metrics: {'mae': 0.43444881092666976, 'r2': -0.5241348213868124, 'rmse': 0.5897411915106154}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:26, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 0.2993515580892563, Val metrics: {'mae': 0.4458842256669376, 'r2': -0.5833317776610727, 'rmse': 0.601084784048828}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:25, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 0.28868870362639426, Val metrics: {'mae': 0.45690438143991075, 'r2': -0.6729927606309496, 'rmse': 0.6178695618413682}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:25, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train loss: 0.2758818969130516, Val metrics: {'mae': 0.4592558245716642, 'r2': -0.7207069873651701, 'rmse': 0.626618526981728}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:26, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train loss: 0.27912004888057707, Val metrics: {'mae': 0.44715835399006526, 'r2': -0.5982601712242293, 'rmse': 0.6039117905296998}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:26, 10.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train loss: 0.2834742233157158, Val metrics: {'mae': 0.44384483381062534, 'r2': -0.5849991529565042, 'rmse': 0.6014011960018354}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 20/296 [00:01<00:25, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train loss: 0.2772685319185257, Val metrics: {'mae': 0.44986738136243254, 'r2': -0.5758220379729724, 'rmse': 0.5996576177671246}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = None\n",
    "best_val_metric = -math.inf if higher_is_better else math.inf\n",
    "task_b_model.to(device)\n",
    "best_epoch = 0\n",
    "early_stop = 20\n",
    "# train\n",
    "for epoch in range(1, epochs + 1):\n",
    "    task_b_model.train()\n",
    "    \n",
    "    cnt = 0\n",
    "    loss_accum = count_accum = 0\n",
    "    for batch in tqdm(taskb_loader_dict[\"train\"]):\n",
    "        cnt += 1\n",
    "        if cnt > early_stop:\n",
    "            break\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = task_b_model(\n",
    "            batch,\n",
    "            task_b.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "        loss = loss_fn(pred, batch[task_b.entity_table].y.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_accum += loss.detach().item() * pred.size(0)\n",
    "        count_accum += pred.size(0)\n",
    "\n",
    "    train_loss = loss_accum / count_accum\n",
    "    val_pred_hat = task_b.get_table(\"val\").df[task_b.target_col].to_numpy()\n",
    "    val_logits = test(taskb_loader_dict[\"val\"], task_b_model, task_b)\n",
    "    val_logits = val_logits.numpy()\n",
    "    \n",
    "    val_metrics = {\n",
    "        \"mae\": mean_absolute_error(val_pred_hat, val_logits),\n",
    "        \"r2\": r2_score(val_pred_hat, val_logits),\n",
    "        \"rmse\": root_mean_squared_error(val_pred_hat, val_logits),\n",
    "    }\n",
    "    \n",
    "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
    "\n",
    "    \n",
    "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
    "        not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
    "    ):\n",
    "        best_epoch = epoch\n",
    "        best_val_metric = val_metrics[tune_metric]\n",
    "        state_dict = copy.deepcopy(task_b_model.state_dict())\n",
    "\n",
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.4060025686323995,\n",
       " 'r2': -0.32183112975279005,\n",
       " 'rmse': 0.5532634466844648}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "task_b_model.load_state_dict(state_dict)\n",
    "logits = test(taskb_loader_dict[\"test\"], task_b_model, task_b)\n",
    "logits = logits.numpy()\n",
    "pred_hat = task_b.get_table(\"test\", mask_input_cols=False).df[task_b.target_col].to_numpy()\n",
    "test_metrics = {\n",
    "        \"mae\": mean_absolute_error(pred_hat, logits),\n",
    "        \"r2\": r2_score(pred_hat, logits),\n",
    "        \"rmse\": root_mean_squared_error(pred_hat, logits),\n",
    "}\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task_b_model load, freeze and fine-tune in task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a_model.reset_parameters()\n",
    "task_b_model.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(\"task_b_model.pth\")\n",
    "task_b_model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 0.4100478495823158,\n",
       " 'r2': -0.5215441797977363,\n",
       " 'rmse': 0.5935895870078363}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "logits = test(taskb_loader_dict[\"test\"], task_b_model, task_b)\n",
    "logits = logits.numpy()\n",
    "pred_hat = task_b.get_table(\"test\", mask_input_cols=False).df[task_b.target_col].to_numpy()\n",
    "test_metrics = {\n",
    "        \"mae\": mean_absolute_error(pred_hat, logits),\n",
    "        \"r2\": r2_score(pred_hat, logits),\n",
    "        \"rmse\": root_mean_squared_error(pred_hat, logits),\n",
    "}\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether the model is frozen in task_b_model\n",
    "# for name, param in task_a_model.named_parameters():\n",
    "#     if not param.requires_grad:\n",
    "#         print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Task A\n",
    "optimizer = torch.optim.Adam(task_a_model.parameters(), lr=0.005)\n",
    "epochs = 15\n",
    "loss_fn = BCEWithLogitsLoss()\n",
    "tune_metric = \"auroc\"\n",
    "higher_is_better = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/24 [00:00<00:03,  6.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 0.6657383552546976, Val metrics: {'auroc': 0.6363636363636364, 'accuracy': 0.6229166666666667, 'precision': 0.6478454680534919, 'recall': 0.7771836007130125, 'f1': 0.706645056726094}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 0.6018843909929609, Val metrics: {'auroc': 0.6720008577593717, 'accuracy': 0.6385416666666667, 'precision': 0.6573529411764706, 'recall': 0.7967914438502673, 'f1': 0.7203867848509267}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 0.5897108795882583, Val metrics: {'auroc': 0.6694499171279358, 'accuracy': 0.6447916666666667, 'precision': 0.6498637602179836, 'recall': 0.8502673796791443, 'f1': 0.7366795366795367}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  7.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 0.5781220834772448, Val metrics: {'auroc': 0.6626771920889568, 'accuracy': 0.615625, 'precision': 0.6371428571428571, 'recall': 0.7950089126559715, 'f1': 0.7073750991276765}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 0.5663542633496346, Val metrics: {'auroc': 0.665022627870925, 'accuracy': 0.6395833333333333, 'precision': 0.6431424766977364, 'recall': 0.8609625668449198, 'f1': 0.7362804878048781}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  7.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train loss: 0.557119338407464, Val metrics: {'auroc': 0.663767261290481, 'accuracy': 0.6145833333333334, 'precision': 0.6423248882265276, 'recall': 0.768270944741533, 'f1': 0.6996753246753247}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train loss: 0.5531355584981701, Val metrics: {'auroc': 0.6667292116208525, 'accuracy': 0.63125, 'precision': 0.6716417910447762, 'recall': 0.7219251336898396, 'f1': 0.6958762886597938}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train loss: 0.5408712819713105, Val metrics: {'auroc': 0.670146846617435, 'accuracy': 0.6416666666666667, 'precision': 0.6472184531886025, 'recall': 0.8502673796791443, 'f1': 0.7349768875192604}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train loss: 0.5303818412089082, Val metrics: {'auroc': 0.659992226555694, 'accuracy': 0.6322916666666667, 'precision': 0.676271186440678, 'recall': 0.7112299465240641, 'f1': 0.6933101650738488}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.5214789944409092, Val metrics: {'auroc': 0.6278664575878199, 'accuracy': 0.603125, 'precision': 0.6505016722408027, 'recall': 0.6934046345811051, 'f1': 0.6712683347713546}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  7.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 0.5181294286352447, Val metrics: {'auroc': 0.6630882017878922, 'accuracy': 0.6239583333333333, 'precision': 0.6773049645390071, 'recall': 0.6809269162210339, 'f1': 0.6791111111111111}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  7.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 0.5037265925262697, Val metrics: {'auroc': 0.6608276484437474, 'accuracy': 0.6197916666666666, 'precision': 0.6380281690140845, 'recall': 0.8074866310160428, 'f1': 0.7128245476003147}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 0.49312296955510343, Val metrics: {'auroc': 0.6622304424162009, 'accuracy': 0.615625, 'precision': 0.6415929203539823, 'recall': 0.7754010695187166, 'f1': 0.7021791767554479}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  6.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 0.49578280023123517, Val metrics: {'auroc': 0.6600100965426043, 'accuracy': 0.6135416666666667, 'precision': 0.6409495548961425, 'recall': 0.7700534759358288, 'f1': 0.6995951417004048}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:03<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 0.47899952708770377, Val metrics: {'auroc': 0.6566237340231149, 'accuracy': 0.6208333333333333, 'precision': 0.6508422664624809, 'recall': 0.7575757575757576, 'f1': 0.700164744645799}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = None\n",
    "best_val_metric = -math.inf if higher_is_better else math.inf\n",
    "task_a_model.to(device)\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    task_a_model.train()\n",
    "    loss_accum = count_accum = 0\n",
    "    for batch in tqdm(taska_loader_dict[\"train\"]):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = task_a_model(\n",
    "            batch,\n",
    "            task_a.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "        loss = loss_fn(pred, batch[task_a.entity_table].y.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_accum += loss.detach().item() * pred.size(0)\n",
    "        count_accum += pred.size(0)\n",
    "    \n",
    "    train_loss = loss_accum / count_accum\n",
    "    val_logits = test(taska_loader_dict[\"val\"], task_a_model, task_a)\n",
    "    val_logits = torch.sigmoid(val_logits).numpy()\n",
    "    \n",
    "    val_pred = (val_logits > 0.5).astype(int)\n",
    "    val_pred_hat = task_a.get_table(\"val\").df[task_a.target_col].to_numpy()\n",
    "    val_metrics = {\n",
    "            \"auroc\": roc_auc_score(val_pred_hat, val_logits),\n",
    "        \"accuracy\": accuracy_score(val_pred_hat, val_pred),\n",
    "        \"precision\": precision_score(val_pred_hat, val_pred),\n",
    "        \"recall\": recall_score(val_pred_hat, val_pred),\n",
    "        \"f1\": f1_score(val_pred_hat, val_pred),\n",
    "    }\n",
    "    \n",
    "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
    "\n",
    "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
    "        not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
    "    ):\n",
    "        best_epoch = epoch\n",
    "        best_val_metric = val_metrics[tune_metric]\n",
    "        state_dict = copy.deepcopy(task_a_model.state_dict())\n",
    "\n",
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auroc': 0.7135955831608005,\n",
       " 'accuracy': 0.6593939393939394,\n",
       " 'precision': 0.6778169014084507,\n",
       " 'recall': 0.7971014492753623,\n",
       " 'f1score': 0.7326355851569933}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test task A\n",
    "task_a_model.load_state_dict(state_dict)\n",
    "test_logits = test(taska_loader_dict[\"test\"], task_a_model, task_a)\n",
    "test_logits =  torch.sigmoid(test_logits).numpy()\n",
    "\n",
    "test_pred = (test_logits > 0.5).astype(int)\n",
    "test_pred_hat = task_a.get_table(\"test\", mask_input_cols = False).df[task_a.target_col].to_numpy()\n",
    "test_metrics = {\n",
    "    \"auroc\": roc_auc_score(test_pred_hat, test_logits),\n",
    "    \"accuracy\": accuracy_score(test_pred_hat, test_pred),\n",
    "    \"precision\": precision_score(test_pred_hat, test_pred),\n",
    "    \"recall\": recall_score(test_pred_hat, test_pred),\n",
    "    \"f1score\": f1_score(test_pred_hat, test_pred),\n",
    "}\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
