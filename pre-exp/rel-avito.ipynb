{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lingze/embedding_fusion\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import relbench\n",
    "from relbench.base import Table, Database, Dataset, EntityTask\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "from relbench.base import BaseTask\n",
    "from torch_geometric.seed import seed_everything\n",
    "from relbench.modeling.utils import get_stype_proposal\n",
    "from relbench.modeling.graph import make_pkey_fkey_graph\n",
    "from relbench.modeling.graph import get_node_train_table_input\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch_geometric\n",
    "import torch_frame\n",
    "\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "from typing import List, Optional\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from torch.nn import L1Loss, BCEWithLogitsLoss\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/rel-avito/db...\n",
      "Done in 5.57 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(name=\"rel-avito\", download=True)\n",
    "db = dataset.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "col_to_stype_dict = get_stype_proposal(db)\n",
    "\n",
    "class GloveTextEmbedding:\n",
    "    def __init__(self, device: Optional[torch.device\n",
    "                                       ] = None):\n",
    "        self.model = SentenceTransformer(\n",
    "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def __call__(self, sentences: List[str]) -> Tensor:\n",
    "        return torch.from_numpy(self.model.encode(sentences))\n",
    "\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=GloveTextEmbedding(device=device), batch_size=256\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/lingze/embedding_fusion/data\"\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    db,\n",
    "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
    "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
    "    cache_dir=os.path.join(\n",
    "        root_dir, f\"rel-avito_materialized_cache\"\n",
    "    ),  # store materialized graph for convenience\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = get_task(\"rel-avito\", \"user-ad-visit\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relbench.modeling.graph import get_link_train_table_input, make_pkey_fkey_graph\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from relbench.modeling.loader import LinkNeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/rel-avito/db...\n",
      "Done in 6.31 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/relbench/modeling/graph.py:217: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at ../aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n",
      "  dst_node_indices = sparse_coo.to_sparse_csr()\n"
     ]
    }
   ],
   "source": [
    "neighbors = 128\n",
    "batch_size = 512\n",
    "n = 30_000\n",
    "train_table_input = get_link_train_table_input(task.get_table(\"train\"), task)\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data = data,\n",
    "    num_neighbors = neighbors,\n",
    "    time_attr=\"time\",\n",
    "    src_nodes = train_table_input.src_nodes,\n",
    "    dst_nodes=train_table_input.dst_nodes,\n",
    "    num_dst_nodes=train_table_input.num_dst_nodes,\n",
    "    src_time=train_table_input.src_time,\n",
    "    share_same_time=False,\n",
    "    batch_size=batch_size,\n",
    "    temporal_strategy=\"uniform\",\n",
    "    shuffle= True,\n",
    "    num_workers=0,\n",
    ")\n",
    "# train_loader = LinkNeighborLoader(\n",
    "#     data = data,\n",
    "#     num_neighbors = neighbors,\n",
    "#     time_attr=\"time\",\n",
    "#     src_nodes = (train_table_input.src_nodes[0], train_table_input.src_nodes[1][:n]),\n",
    "#     dst_nodes=(train_table_input.dst_nodes[0], train_table_input.dst_nodes[1][:n]),\n",
    "#     num_dst_nodes=train_table_input.num_dst_nodes,\n",
    "#     src_time=train_table_input.src_time,\n",
    "#     share_same_time=False,\n",
    "#     batch_size=batch_size,\n",
    "#     temporal_strategy=\"uniform\",\n",
    "#     shuffle= True,\n",
    "#     num_workers=0,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val and test loader\n",
    "eval_loaders_dict = {}\n",
    "for split in [\"val\", \"test\"]:\n",
    "    ts = dataset.val_timestamp if split == \"val\" else dataset.test_timestamp\n",
    "    seed_time = int(ts.timestamp())\n",
    "    target_table =  task.get_table(split)\n",
    "    src_node_indices = torch.from_numpy(target_table.df[task.src_entity_col].values)\n",
    "    \n",
    "    src_loader = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors = neighbors,\n",
    "        time_attr = \"time\",\n",
    "        input_nodes=(task.src_entity_table, src_node_indices),\n",
    "        input_time = torch.full(\n",
    "            size=(len(src_node_indices),), fill_value = seed_time, dtype=torch.long\n",
    "        ),\n",
    "        batch_size = batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers = 0,\n",
    "    )\n",
    "    \n",
    "    dst_loader = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors= neighbors,\n",
    "        time_attr = \"time\",\n",
    "        input_nodes = task.dst_entity_table,\n",
    "        input_time = torch.full(\n",
    "            size = (task.num_dst_nodes,), fill_value = seed_time, dtype = torch.long\n",
    "        ),\n",
    "        batch_size = batch_size,\n",
    "        shuffle = False,\n",
    "        num_workers = 0,\n",
    "    )\n",
    "    eval_loaders_dict[split] = (src_loader, dst_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.base import CompositeModel, FeatureEncodingPart, NodeRepresentationPart\n",
    "from relbench.modeling.nn import HeteroTemporalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 128\n",
    "temporal_encoder = HeteroTemporalEncoder(\n",
    "    node_types=[\n",
    "            node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
    "        ],\n",
    "        channels=channels,\n",
    ")\n",
    "\n",
    "feat_encoder = FeatureEncodingPart(\n",
    "    data = data,\n",
    "    node_to_col_stats=col_stats_dict,\n",
    "    channels = channels,\n",
    ")\n",
    "\n",
    "node_encoder = NodeRepresentationPart(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    num_layers=1,\n",
    "    normalization=\"layer_norm\",\n",
    "    dropout_prob=0.2\n",
    ")\n",
    "\n",
    "model =  CompositeModel(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    out_channels=1,\n",
    "    dropout=0.2,\n",
    "    aggr=\"mean\",\n",
    "    norm=\"layer_norm\",\n",
    "    num_layer=2,\n",
    "    feature_encoder=feat_encoder,\n",
    "    node_encoder=node_encoder,\n",
    "    temporal_encoder=temporal_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relbench.metrics import link_prediction_map, link_prediction_precision, link_prediction_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "\n",
    "eval_epochs_interval = 0\n",
    "max_step_per_epoch = 100\n",
    "total_steps = min(len(train_loader), max_step_per_epoch)\n",
    "eval_k = 10\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    loss_accum = count_accum = 0\n",
    "    steps = 0\n",
    "    for batch in tqdm(train_loader, total = total_steps):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        src_batch, batch_pos_dst, batch_neg_dst = batch\n",
    "        src_batch, batch_pos_dst, batch_neg_dst = (\n",
    "            src_batch.to(device),\n",
    "            batch_pos_dst.to(device),\n",
    "            batch_neg_dst.to(device),\n",
    "        )\n",
    "        \n",
    "        x_src = model(src_batch, task.src_entity_table)\n",
    "        x_pos_dst = model(batch_pos_dst, task.dst_entity_table)\n",
    "        x_neg_dst = model(batch_neg_dst, task.dst_entity_table)\n",
    "        \n",
    "        # [batch_size, ]\n",
    "        pos_score = torch.sum(x_src*x_pos_dst, dim = 1)\n",
    "        neg_score = torch.sum(x_src*x_neg_dst, dim = 1)\n",
    "        \n",
    "        diff_score = pos_score - neg_score\n",
    "        loss = torch.nn.functional.softplus(-diff_score).mean()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_accum += float(loss) * x_src.size(0)\n",
    "        count_accum += x_src.size(0)\n",
    "        \n",
    "        steps += 1 \n",
    "        if steps >= total_steps:\n",
    "            break\n",
    "\n",
    "    train_loss = loss_accum / count_accum if count_accum > 0 else float(\"nan\")\n",
    "    \n",
    "    if epoch % eval_epochs_interval == 0:\n",
    "        model.eval()\n",
    "        dst_embs:list[Tensor] = []\n",
    "        src_loader, dst_loader = eval_loaders_dict[\"val\"]\n",
    "        for batch in tqdm(dst_loader):\n",
    "            batch = batch.to(device)\n",
    "            emb = model(batch, task.dst_entity_table).detach()\n",
    "            dst_embs.append(emb)\n",
    "        dst_emb = torch.cat(dst_embs, dim = 0)\n",
    "        del dst_embs\n",
    "        \n",
    "        pred_index_mat_list: list[Tensor] = []\n",
    "        for batch in tqdm(src_loader):\n",
    "            batch = batch.to(device)\n",
    "            emb = model(batch, task.src_entity_table).detach()\n",
    "            _, pred_index_mat = torch.topk(emb @ dst_emb.t(), k = 10, dim = 1)\n",
    "            pred_index_mat_list.append(pred_index_mat)\n",
    "        \n",
    "        pred = torch.cat(pred_index_mat_list, dim = 0).numpy()\n",
    "        val_table = task.get_table(\"val\", mask_input_cols=False)\n",
    "        \n",
    "        expect_pred_shape = (len(val_table), eval_k)\n",
    "        assert pred.shape == expect_pred_shape, f\"Expected shape {expect_pred_shape}, got {pred.shape}\"\n",
    "        \n",
    "        pred_isin_list = []\n",
    "        dst_count_list = []\n",
    "        for true_dst_nodes, pred_dst_nodes in zip(\n",
    "            val_table.df[task.dst_entity_col], pred\n",
    "        ):\n",
    "            pred_isin_list.append(\n",
    "                np.isin(np.array(pred_dst_nodes), np.array(true_dst_nodes))\n",
    "            )\n",
    "            dst_count_list.append(len(true_dst_nodes))\n",
    "        pred_isin = np.stack(pred_isin_list)\n",
    "        dst_count = np.array(dst_count_list)\n",
    "\n",
    "        val_metrics = {\n",
    "            \"map\": link_prediction_map(pred_isin, dst_count),\n",
    "            \"precision\": link_prediction_precision(pred_isin, dst_count),\n",
    "            \"recall\": link_prediction_recall(pred_isin, dst_count),\n",
    "        }\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
