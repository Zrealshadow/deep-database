{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct self-supervised learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lingze/embedding_fusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ..\n",
    "from model.base import CompositeModel, FeatureEncodingPart, NodeRepresentationPart\n",
    "from model.utils import InfoNCE\n",
    "from relbench.modeling.nn import HeteroTemporalEncoder\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.tasks import get_task\n",
    "from relbench.base import BaseTask\n",
    "from torch_geometric.seed import seed_everything\n",
    "from relbench.modeling.utils import get_stype_proposal\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/rel-trial/db...\n",
      "Done in 7.74 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(name=\"rel-trial\", download = True)\n",
    "db = dataset.get_db()\n",
    "task_a = get_task(\"rel-trial\", \"study-outcome\", download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame import stype\n",
    "from torch import Tensor\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from typing import List, Optional\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "col_to_stype_dict = get_stype_proposal(db)\n",
    "\n",
    "class GloveTextEmbedding:\n",
    "    def __init__(self, device: Optional[torch.device\n",
    "                                       ] = None):\n",
    "        self.model = SentenceTransformer(\n",
    "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def __call__(self, sentences: List[str]) -> Tensor:\n",
    "        return torch.from_numpy(self.model.encode(sentences))\n",
    "\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=GloveTextEmbedding(device=device), batch_size=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Rule 0] Convert interventions.intervention_id from numerical to categorical data\n",
      "Unique value: 3462, Count value: 3462\n",
      "[Rule 0] Convert interventions_studies.id from numerical to categorical data\n",
      "Unique value: 171771, Count value: 171771\n",
      "[Rule 0] Convert interventions_studies.nct_id from numerical to categorical data\n",
      "Unique value: 90364, Count value: 171771\n",
      "[Rule 0] Convert interventions_studies.intervention_id from numerical to categorical data\n",
      "Unique value: 3432, Count value: 171771\n",
      "[Rule 0] Convert facilities_studies.id from numerical to categorical data\n",
      "Unique value: 1798765, Count value: 1798765\n",
      "[Rule 0] Convert facilities_studies.nct_id from numerical to categorical data\n",
      "Unique value: 227838, Count value: 1798765\n",
      "[Rule 0] Convert facilities_studies.facility_id from numerical to categorical data\n",
      "Unique value: 431513, Count value: 1798765\n",
      "[Rule 0] Convert sponsors.sponsor_id from numerical to categorical data\n",
      "Unique value: 53241, Count value: 53241\n",
      "[Rule 0] Convert sponsors.agency_class from text_embedded to categorical data\n",
      "Unique value: 9, Count value: 53241\n",
      "[Rule 0] Convert eligibilities.id from numerical to categorical data\n",
      "Unique value: 249730, Count value: 249730\n",
      "[Rule 0] Convert eligibilities.nct_id from numerical to categorical data\n",
      "Unique value: 249730, Count value: 249730\n",
      "[Rule 1] Convert eligibilities.minimum_age from text_embedded to categorical data\n",
      "Unique value: 289, Count value: 234048\n",
      "[Rule 1] Convert eligibilities.maximum_age from text_embedded to categorical data\n",
      "Unique value: 435, Count value: 132548\n",
      "[Rule 0] Convert reported_event_totals.id from numerical to categorical data\n",
      "Unique value: 383064, Count value: 383064\n",
      "[Rule 0] Convert reported_event_totals.nct_id from numerical to categorical data\n",
      "Unique value: 52751, Count value: 383064\n",
      "[Rule 0] Convert designs.id from numerical to categorical data\n",
      "Unique value: 249093, Count value: 249093\n",
      "[Rule 0] Convert designs.nct_id from numerical to categorical data\n",
      "Unique value: 249093, Count value: 249093\n",
      "[Rule 0] Convert designs.observational_model from text_embedded to categorical data\n",
      "Unique value: 10, Count value: 47428\n",
      "[Rule 1] Convert designs.primary_purpose from text_embedded to categorical data\n",
      "Unique value: 11, Count value: 194280\n",
      "[Rule 0] Convert conditions_studies.id from numerical to categorical data\n",
      "Unique value: 408422, Count value: 408422\n",
      "[Rule 0] Convert conditions_studies.nct_id from numerical to categorical data\n",
      "Unique value: 203786, Count value: 408422\n",
      "[Rule 0] Convert conditions_studies.condition_id from numerical to categorical data\n",
      "Unique value: 3924, Count value: 408422\n",
      "[Rule 0] Convert drop_withdrawals.id from numerical to categorical data\n",
      "Unique value: 381199, Count value: 381199\n",
      "[Rule 0] Convert drop_withdrawals.nct_id from numerical to categorical data\n",
      "Unique value: 32129, Count value: 381199\n",
      "[Rule 1] Convert drop_withdrawals.period from text_embedded to categorical data\n",
      "Unique value: 7039, Count value: 381199\n",
      "[Rule 0] Convert studies.nct_id from numerical to categorical data\n",
      "Unique value: 249730, Count value: 249730\n",
      "[Rule 1] Convert studies.biospec_retention from text_embedded to categorical data\n",
      "Unique value: 4, Count value: 10095\n",
      "[Rule 0] Convert studies.source_class from text_embedded to categorical data\n",
      "Unique value: 8, Count value: 249730\n",
      "[Rule 0] Convert outcome_analyses.id from numerical to categorical data\n",
      "Unique value: 225846, Count value: 225846\n",
      "[Rule 0] Convert outcome_analyses.nct_id from numerical to categorical data\n",
      "Unique value: 18222, Count value: 225846\n",
      "[Rule 0] Convert outcome_analyses.outcome_id from numerical to categorical data\n",
      "Unique value: 92853, Count value: 225846\n",
      "[Rule 0] Convert outcome_analyses.non_inferiority_type from text_embedded to categorical data\n",
      "Unique value: 8, Count value: 225846\n",
      "[Rule 0] Convert outcome_analyses.param_type from text_embedded to categorical data\n",
      "Unique value: 4751, Count value: 152430\n",
      "[Rule 1] Convert outcome_analyses.method from text_embedded to categorical data\n",
      "Unique value: 3340, Count value: 194999\n",
      "[Rule 0] Convert sponsors_studies.id from numerical to categorical data\n",
      "Unique value: 391462, Count value: 391462\n",
      "[Rule 0] Convert sponsors_studies.nct_id from numerical to categorical data\n",
      "Unique value: 249730, Count value: 391462\n",
      "[Rule 0] Convert sponsors_studies.sponsor_id from numerical to categorical data\n",
      "Unique value: 48796, Count value: 391462\n",
      "[Rule 0] Convert outcomes.id from numerical to categorical data\n",
      "Unique value: 411933, Count value: 411933\n",
      "[Rule 0] Convert outcomes.nct_id from numerical to categorical data\n",
      "Unique value: 52941, Count value: 411933\n",
      "[Rule 0] Convert outcomes.dispersion_type from text_embedded to categorical data\n",
      "Unique value: 36, Count value: 250950\n",
      "[Rule 0] Convert conditions.condition_id from numerical to categorical data\n",
      "Unique value: 3973, Count value: 3973\n",
      "[Rule 0] Convert facilities.facility_id from numerical to categorical data\n",
      "Unique value: 453233, Count value: 453233\n",
      "[Rule 0] Convert facilities.city from text_embedded to categorical data\n",
      "Unique value: 28166, Count value: 453221\n",
      "[Rule 0] Convert facilities.state from text_embedded to categorical data\n",
      "Unique value: 7723, Count value: 225929\n",
      "[Rule 0] Convert facilities.zip from text_embedded to categorical data\n",
      "Unique value: 48348, Count value: 353213\n",
      "[Rule 1] Convert facilities.country from text_embedded to categorical data\n",
      "Unique value: 211, Count value: 453221\n"
     ]
    }
   ],
   "source": [
    "# preprocess col_to_stype_dict using our own rules\n",
    "\n",
    "# rule 0\n",
    "# based on the column name\n",
    "# we predefined some\n",
    "numerical_keywords = [\n",
    "    'count', 'num', 'amount', 'total', 'length', 'height', 'value', 'rate',  'number',\n",
    "    'score', 'level', 'size', 'price', 'percent', 'ratio', 'volume', 'index', 'avg', 'max', 'min'\n",
    "]\n",
    "categorical_keywords = [\n",
    "    'type', 'category', 'class', 'label', 'status', 'code', 'id',\n",
    "    'region', 'zone', 'flag', 'is_', 'has_', 'mode', 'city', 'state', 'zip'\n",
    "]\n",
    "\n",
    "text_keywords = [\n",
    "    'description', 'comments', 'content', 'name', 'review', 'message', 'note', 'query', 'summary'\n",
    "]\n",
    "\n",
    "\n",
    "# rule 1\n",
    "# unique_value < 0.02 * total_value -> categorical data\n",
    "# rule 1, general rule for text and numerical data\n",
    "\n",
    "for table_name, table in db.table_dict.items():\n",
    "    df = table.df\n",
    "\n",
    "    for col_name in df.columns:\n",
    "        if col_name not in col_to_stype_dict[table_name]:\n",
    "            continue\n",
    "        guess_type = col_to_stype_dict[table_name][col_name]\n",
    "\n",
    "        # rule 0\n",
    "        if any([kw in col_name.lower() for kw in text_keywords]):\n",
    "            if guess_type == stype.text_embedded:\n",
    "                continue\n",
    "\n",
    "        if any([kw in col_name.lower() for kw in numerical_keywords]):\n",
    "            # check the data can be converted to numerical data\n",
    "            is_convertible = (\n",
    "                pd.to_numeric(df[col_name], errors='coerce').notna()\n",
    "                + df[col_name].isna()).all()\n",
    "            \n",
    "            if is_convertible:\n",
    "                if guess_type != stype.numerical:\n",
    "                    print(\n",
    "                        f\"[Rule 0] Convert {table_name}.{col_name} from {guess_type} to numerical data\")\n",
    "                col_to_stype_dict[table_name][col_name] = stype.numerical\n",
    "                continue\n",
    "\n",
    "        unique_value = len(df[col_name].unique())\n",
    "        count_value = (~df[col_name].isna()).sum()\n",
    "\n",
    "        if any([kw in col_name.lower() for kw in categorical_keywords]):\n",
    "            if guess_type != stype.categorical:\n",
    "                # print the unique value and count value for check\n",
    "                print(\n",
    "                    f\"[Rule 0] Convert {table_name}.{col_name} from {guess_type} to categorical data\")\n",
    "                print(\n",
    "                    f\"Unique value: {unique_value}, Count value: {count_value}\")\n",
    "\n",
    "            col_to_stype_dict[table_name][col_name] = stype.categorical\n",
    "            continue\n",
    "\n",
    "        # rule 1\n",
    "        if guess_type == stype.categorical or guess_type == stype.timestamp:\n",
    "            continue\n",
    "        # check whether can convert to numerical\n",
    "        is_convertible = (\n",
    "            pd.to_numeric(df[col_name], errors='coerce').notna()\n",
    "            + df[col_name].isna()).all()\n",
    "        \n",
    "        if is_convertible and guess_type == stype.numerical:\n",
    "            continue\n",
    "\n",
    "        # for  type  numerical or text_embedding check Rule 1\n",
    "        if unique_value*1.0 / count_value < 0.02:\n",
    "            # minimum average frequency is 50.\n",
    "            col_to_stype_dict[table_name][col_name] = stype.categorical\n",
    "            print(\n",
    "                f\"[Rule 1] Convert {table_name}.{col_name} from {guess_type} to categorical data\")\n",
    "            print(f\"Unique value: {unique_value}, Count value: {count_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build heterogeneous graph.\n",
    "# remove the primary key\n",
    "from relbench.modeling.graph import make_pkey_fkey_graph\n",
    "root_dir = \"/home/lingze/embedding_fusion/data\"\n",
    "data, col_stats_dict = make_pkey_fkey_graph(\n",
    "    db,\n",
    "    col_to_stype_dict=col_to_stype_dict,  # speficied column types\n",
    "    text_embedder_cfg=text_embedder_cfg,  # our chosen text encoder\n",
    "    cache_dir=os.path.join(\n",
    "        root_dir, f\"rel-trial_materialized_cache\"\n",
    "    ),  # store materialized graph for convenience\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct input node loader\n",
    "BATCH_SIZE = 512\n",
    "def to_unix_time(ser: pd.Series) -> np.ndarray:\n",
    "    r\"\"\"Converts a :class:`pandas.Timestamp` series to UNIX timestamp (in seconds).\"\"\"\n",
    "    assert ser.dtype in [np.dtype(\"datetime64[s]\"), np.dtype(\"datetime64[ns]\")]\n",
    "    unix_time = ser.astype(\"int64\").values\n",
    "    if ser.dtype == np.dtype(\"datetime64[ns]\"):\n",
    "        unix_time //= 10**9\n",
    "    return unix_time\n",
    "\n",
    "def generate_loader(entity_table: str, node_idxs: Tensor):\n",
    "    nodes = (entity_table, node_idxs)\n",
    "    n = node_idxs.size(0)\n",
    "    # set the time to the db max timestamp\n",
    "    time_series = pd.Series([db.max_timestamp] * n)\n",
    "    input_time = torch.from_numpy(to_unix_time(time_series))\n",
    "    # no temporal information, we use max_timestamp in training\n",
    "    loader = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors= [\n",
    "            128 for i in range(2)\n",
    "        ], # number of neighbors to sample for each layer\n",
    "        input_nodes = nodes,\n",
    "        time_attr = \"time\",\n",
    "        input_time = input_time,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers = 0,\n",
    "    )\n",
    "    return loader    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'studies'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_table = task_a.entity_table\n",
    "entity_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct bottom model\n",
    "channels = 64\n",
    "temporal_encoder = HeteroTemporalEncoder(\n",
    "    node_types=[\n",
    "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
    "            ],\n",
    "    channels=channels,\n",
    ")\n",
    "\n",
    "feat_encoder = FeatureEncodingPart(\n",
    "    data=data,\n",
    "    node_to_col_stats=col_stats_dict,\n",
    "    channels=channels\n",
    ")\n",
    "\n",
    "node_encoder = NodeRepresentationPart(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    num_layers=1,\n",
    "    normalization=\"layer_norm\",\n",
    "    dropout_prob=0.2\n",
    ")\n",
    "\n",
    "\n",
    "net = CompositeModel(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    out_channels=1,\n",
    "    dropout=0.2,\n",
    "    aggr=\"mean\",\n",
    "    norm=\"layer_norm\",\n",
    "    num_layer=2,\n",
    "    feature_encoder=feat_encoder,\n",
    "    node_encoder=node_encoder,\n",
    "    temporal_encoder=temporal_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(249730, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the pre-calculated positive sample index\n",
    "path = './tmp/studies_positive_samples.npy'\n",
    "positive_sample_index = np.load(path)\n",
    "positive_sample_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = torch.from_numpy(db.table_dict[entity_table].df.index.astype(int).values)\n",
    "ssl_loader = generate_loader(entity_table, node_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "negative_num = 20\n",
    "temprature = 0.01\n",
    "net.reset_parameters()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
    "epoches = 20\n",
    "early_restart_steps = 20\n",
    "loss_fn = InfoNCE(temperature=temprature, negative_mode='paired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.021847360279588474\n",
      "Epoch 2, Loss: 0.018506837920064016\n",
      "Epoch 3, Loss: 0.018144231910506885\n",
      "Epoch 4, Loss: 0.01786864921450615\n",
      "Epoch 5, Loss: 0.01788589047888915\n"
     ]
    }
   ],
   "source": [
    "net.to(device)\n",
    "for epoch in range(1, epoches + 1):\n",
    "    net.train()\n",
    "    loss_accum = count_accum = 0\n",
    "    \n",
    "    for cnt, batch in enumerate(ssl_loader):\n",
    "        # early restart new epoch    \n",
    "        if cnt > early_restart_steps:\n",
    "            break\n",
    "        \n",
    "        anchor_nodes = batch[entity_table].n_id.numpy()\n",
    "        B = anchor_nodes.shape[0]\n",
    "        # dynamically to sample positive and negative samples\n",
    "        positive_sample_nodes = []\n",
    "        negative_sample_indexs = []\n",
    "        for anchor_idx, anchor_node in enumerate(anchor_nodes):\n",
    "            # positive sample, just from the pre-calculated positive sample pool\n",
    "            positive_sample_pool = positive_sample_index[anchor_node]\n",
    "            positive_sample_nodes.append(\n",
    "                np.random.choice(positive_sample_pool)\n",
    "            )\n",
    "            \n",
    "            # negative sample, we choose negative samples within the batch\n",
    "            # we sample the negative node index in the batch.\n",
    "            negative_sample_index_pool = np.arange(B)\n",
    "            negative_sample_index_pool = negative_sample_index_pool[negative_sample_index_pool != anchor_idx]\n",
    "            negative_sample_index = np.random.choice(negative_sample_index_pool, negative_num, replace=False)\n",
    "            negative_samples = anchor_nodes[negative_sample_index]\n",
    "            \n",
    "            loop_n = 0\n",
    "            while set(negative_samples.tolist()) & set(positive_sample_pool.tolist()) and loop_n < 5: \n",
    "                negative_sample_index = np.random.choice(negative_sample_index_pool, negative_num, replace=False)\n",
    "                negative_samples = anchor_nodes[negative_sample_index]\n",
    "                loop_n += 1 # avoid infinite loop\n",
    "            \n",
    "            negative_sample_indexs.append(negative_sample_index)\n",
    "        \n",
    "        # generate positive samples neighbors\n",
    "        time_series = pd.Series([db.max_timestamp] * B)\n",
    "        input_time = torch.from_numpy(to_unix_time(time_series))\n",
    "        positive_loader = NeighborLoader(\n",
    "            data,\n",
    "            num_neighbors = [128 for i in range(2)],\n",
    "            input_time= input_time,\n",
    "            time_attr= \"time\",\n",
    "            input_nodes = (entity_table, torch.from_numpy(np.array(positive_sample_nodes)).to(torch.long)),\n",
    "            batch_size = BATCH_SIZE,\n",
    "            shuffle = False,\n",
    "            num_workers = 0,\n",
    "        )\n",
    "        positive_batch = next(iter(positive_loader))\n",
    "        # [B,]\n",
    "        negative_sample_indexs = torch.from_numpy(np.array(negative_sample_indexs)).to(torch.long)\n",
    "        # [B, neg_num]\n",
    "        \n",
    "        # calculate the loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        batch, positive_batch = batch.to(device), positive_batch.to(device)\n",
    "        negative_sample_indexs = negative_sample_indexs.to(device)\n",
    "        \n",
    "        anchor_nodes_embedding = net.get_node_embedding(batch, entity_table)[entity_table]\n",
    "        positive_nodes_embedding = net.get_node_embedding(positive_batch, entity_table)[entity_table]\n",
    "        negative_nodes_embedding = anchor_nodes_embedding[negative_sample_indexs]\n",
    "        \n",
    "        loss = loss_fn(anchor_nodes_embedding, positive_nodes_embedding, negative_nodes_embedding)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_accum += loss.detach().item() \n",
    "        count_accum += B\n",
    "    train_loss = loss_accum / count_accum\n",
    "    print(f\"Epoch {epoch}, Loss: {train_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
