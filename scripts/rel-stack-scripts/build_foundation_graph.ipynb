{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lingze/embedding_fusion\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from relbench.datasets import get_dataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "from typing import List, Optional\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import StackDataset\n",
    "from utils.preprocess import infer_type_in_db\n",
    "from utils.tokenize import tokenize_database\n",
    "from utils.builder import build_pyg_hetero_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = StackDataset(cache_dir=\"/home/lingze/.cache/relbench/stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/stack/db...\n",
      "Done in 10.99 seconds.\n"
     ]
    }
   ],
   "source": [
    "db = dataset.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table tags has 1597 rows\n",
      "Table postHistory has 1175368 rows\n",
      "Table comments has 623967 rows\n",
      "Table badges has 463463 rows\n",
      "Table postTag has 648577 rows\n",
      "Table users has 255360 rows\n",
      "Table postLinks has 77337 rows\n",
      "Table votes has 1317876 rows\n",
      "Table posts has 333893 rows\n"
     ]
    }
   ],
   "source": [
    "for table_name, table in db.table_dict.items():\n",
    "    n = len(table.df)\n",
    "    print(f\"Table {table_name} has {n} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rule 0]: tags Inferred Id from numerical as categorical\n",
      "[rule 0]: postHistory Inferred Id from numerical as categorical\n",
      "[rule 0]: postHistory Inferred PostId from numerical as categorical\n",
      "[rule 0]: postHistory Inferred UserId from numerical as categorical\n",
      "[rule 0]: postHistory Inferred PostHistoryTypeId from numerical as categorical\n",
      "[rule 0]: postHistory Inferred ContentLicense from categorical as text_embedded\n",
      "[rule 1]: postHistory Inferred ContentLicense from text_embedded as categorical\n",
      "[rule 0]: postHistory Inferred RevisionGUID from text_embedded as categorical\n",
      "[rule 0]: comments Inferred Id from numerical as categorical\n",
      "[rule 0]: comments Inferred PostId from numerical as categorical\n",
      "[rule 0]: comments Inferred UserId from numerical as categorical\n",
      "[rule 1]: comments Inferred Score from numerical as categorical\n",
      "[rule 0]: comments Inferred ContentLicense from categorical as text_embedded\n",
      "[rule 1]: comments Inferred ContentLicense from text_embedded as categorical\n",
      "[rule 0]: badges Inferred Id from numerical as categorical\n",
      "[rule 0]: badges Inferred UserId from numerical as categorical\n",
      "[rule 0]: postTag Inferred Id from numerical as categorical\n",
      "[rule 0]: postTag Inferred TagId from numerical as categorical\n",
      "[rule 0]: postTag Inferred PostId from numerical as categorical\n",
      "[rule 0]: users Inferred Id from numerical as categorical\n",
      "[rule 0]: users Inferred AccountId from numerical as categorical\n",
      "[rule 0]: users Inferred WebsiteUrl from text_embedded as categorical\n",
      "[rule 0]: postLinks Inferred Id from numerical as categorical\n",
      "[rule 0]: postLinks Inferred RelatedPostId from numerical as categorical\n",
      "[rule 0]: postLinks Inferred PostId from numerical as categorical\n",
      "[rule 0]: votes Inferred Id from numerical as categorical\n",
      "[rule 0]: votes Inferred UserId from numerical as categorical\n",
      "[rule 0]: votes Inferred PostId from numerical as categorical\n",
      "[rule 0]: votes Inferred VoteTypeId from numerical as categorical\n",
      "[rule 0]: posts Inferred Id from numerical as categorical\n",
      "[rule 0]: posts Inferred OwnerUserId from numerical as categorical\n",
      "[rule 0]: posts Inferred AcceptedAnswerId from numerical as categorical\n",
      "[rule 1]: posts Inferred Score from numerical as categorical\n",
      "[rule 0]: posts Inferred ParentId from numerical as categorical\n",
      "[rule 0]: posts Inferred ContentLicense from categorical as text_embedded\n",
      "[rule 1]: posts Inferred ContentLicense from text_embedded as categorical\n"
     ]
    }
   ],
   "source": [
    "\n",
    "col_type_dict = infer_type_in_db(db, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags.TagName: text_embedded, unique values: 1597/1597 Nan Value: 0/1597\n",
      "postHistory.UserDisplayName: text_embedded, unique values: 3061/1175368 Nan Value: 1150131/1175368\n",
      "postHistory.Text: text_embedded, unique values: 960746/1175368 Nan Value: 114938/1175368\n",
      "postHistory.Comment: text_embedded, unique values: 125619/1175368 Nan Value: 714309/1175368\n",
      "comments.UserDisplayName: text_embedded, unique values: 2222/623967 Nan Value: 612281/623967\n",
      "comments.Text: text_embedded, unique values: 621044/623967 Nan Value: 0/623967\n",
      "badges.Name: text_embedded, unique values: 327/463463 Nan Value: 0/463463\n",
      "users.DisplayName: text_embedded, unique values: 218050/255360 Nan Value: 19/255360\n",
      "users.Location: text_embedded, unique values: 11514/255360 Nan Value: 184185/255360\n",
      "users.AboutMe: text_embedded, unique values: 47461/255360 Nan Value: 205676/255360\n",
      "posts.OwnerDisplayName: text_embedded, unique values: 4531/333893 Nan Value: 325346/333893\n",
      "posts.Title: text_embedded, unique values: 163648/333893 Nan Value: 170145/333893\n",
      "posts.Body: text_embedded, unique values: 333357/333893 Nan Value: 493/333893\n"
     ]
    }
   ],
   "source": [
    "# print text embedding type, profile\n",
    "for table, type_dict in col_type_dict.items():\n",
    "    for col_name, stype in type_dict.items():\n",
    "        if stype == stype.text_embedded:\n",
    "            unique_value = db.table_dict[table].df[col_name].unique()\n",
    "            n = len(unique_value)\n",
    "            nm = len(db.table_dict[table].df)\n",
    "            nan_num = db.table_dict[table].df[col_name].isnull().sum()\n",
    "            print(f\"{table}.{col_name}: {stype}, unique values: {n}/{nm} Nan Value: {nan_num}/{nm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Compressing postHistory text columns: ['UserDisplayName', 'Text', 'Comment']\n",
      "----> Compressing comments text columns: ['UserDisplayName', 'Text']\n",
      "----> Compressing users text columns: ['DisplayName', 'Location', 'AboutMe']\n",
      "----> Compressing posts text columns: ['OwnerDisplayName', 'Title']\n"
     ]
    }
   ],
   "source": [
    "# preprocess the table, concatenate the columns which is text type\n",
    "#        /--- text_col_1 ---/ --- text_col_2 --- / --- text_col_3 --- / \n",
    "# row 1  /------- A   -----/ ------- B   -----  / -----   C  ------- /\n",
    "# -------> Generate a new TexT column\n",
    "# \"text_col_1 is A, text_col_2 is B, text_col_3 is C\"\n",
    "\n",
    "# Therefore, we only need to convert this text column to vector \n",
    "# and drop the original text columns\n",
    "# for saving memory and computation \n",
    "\n",
    "\n",
    "for table_name, type_dict in col_type_dict.items():\n",
    "    # collect the text columns\n",
    "    text_cols = [ col for col, stype in type_dict.items() if stype == stype.text_embedded]\n",
    "    compress_cols = []\n",
    "    # for long text, we still keep it as one column\n",
    "    for col in text_cols:\n",
    "        avg_word_count = db.table_dict[table_name].df[col].dropna().apply(lambda x: len(str(x).split())).mean()\n",
    "        if avg_word_count < 128: # a half of default max length of BERT Max length （256）\n",
    "            # remove the long text cols\n",
    "            compress_cols.append(col)\n",
    "          \n",
    "    \n",
    "    if len(compress_cols) <= 1:\n",
    "        # if only one text column, we do not need to compress\n",
    "        continue\n",
    "    \n",
    "    print(f\"----> Compressing {table_name} text columns: {compress_cols}\")\n",
    "    \n",
    "    df = db.table_dict[table_name].df\n",
    "    compress_text_df = df[compress_cols]\n",
    "    \n",
    "    def row_to_text(row):\n",
    "        if row.isna().all():\n",
    "            return None\n",
    "        tokens = [f\"{key} is {value}\" for key, value in row.dropna().items()]\n",
    "        return \", \".join(tokens)\n",
    "\n",
    "    text_list = compress_text_df.apply(row_to_text, axis=1).tolist()\n",
    "    \n",
    "    # drop the compressed columns\n",
    "    df.drop(columns=compress_cols, inplace=True)\n",
    "    df[\"text_compress\"] = text_list\n",
    "    \n",
    "    # update the type dict\n",
    "    for col in compress_cols:\n",
    "        type_dict.pop(col)\n",
    "    type_dict[\"text_compress\"] = stype.text_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class GloveTextEmbedding:\n",
    "    def __init__(self, device: Optional[torch.device\n",
    "                                       ] = None):\n",
    "        self.model = SentenceTransformer(\n",
    "            # \"all-MiniLM-L12-v2\",\n",
    "            \"sentence-transformers/average_word_embeddings_glove.6B.300d\",\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def __call__(self, sentences: List[str]) -> Tensor:\n",
    "        return torch.from_numpy(self.model.encode(sentences))\n",
    "\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=GloveTextEmbedding(device=device), batch_size=512\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> Materialize tags Tensor Frame\n",
      "-----> Materialize postHistory Tensor Frame\n",
      "-----> Materialize comments Tensor Frame\n",
      "-----> Materialize badges Tensor Frame\n",
      "-----> Build edge between posts and tags\n",
      "-----> Materialize users Tensor Frame\n",
      "-----> Materialize postLinks Tensor Frame\n",
      "-----> Materialize votes Tensor Frame\n",
      "-----> Materialize posts Tensor Frame\n"
     ]
    }
   ],
   "source": [
    "cache_dir = \"./data/stack-tensor-frame\"\n",
    "data, col_stats_dict = build_pyg_hetero_graph(\n",
    "    db,\n",
    "    col_type_dict,\n",
    "    text_embedder_cfg,\n",
    "    cache_dir,\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
