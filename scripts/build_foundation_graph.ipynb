{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lingze/embedding_fusion\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from relbench.datasets import get_dataset\n",
    "from relbench.base import Table\n",
    "from tqdm import tqdm\n",
    "from typing import Any,Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch import Tensor\n",
    "from torch_frame import stype\n",
    "from torch_frame.config import TextEmbedderConfig\n",
    "from torch_frame.data import Dataset\n",
    "from torch_frame.data.stats import StatType\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.typing import NodeType\n",
    "from torch_geometric.utils import sort_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/rel-trial/db...\n",
      "Done in 7.58 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(name = \"rel-trial\", download = True)\n",
    "db = dataset.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rule 0]: interventionsInferred intervention_id from numerical as categorical\n",
      "[rule 0]: interventions_studiesInferred id from numerical as categorical\n",
      "[rule 0]: interventions_studiesInferred nct_id from numerical as categorical\n",
      "[rule 0]: interventions_studiesInferred intervention_id from numerical as categorical\n",
      "[rule 0]: facilities_studiesInferred id from numerical as categorical\n",
      "[rule 0]: facilities_studiesInferred nct_id from numerical as categorical\n",
      "[rule 0]: facilities_studiesInferred facility_id from numerical as categorical\n",
      "[rule 0]: sponsorsInferred sponsor_id from numerical as categorical\n",
      "[rule 0]: eligibilitiesInferred id from numerical as categorical\n",
      "[rule 0]: eligibilitiesInferred nct_id from numerical as categorical\n",
      "[rule 0]: reported_event_totalsInferred id from numerical as categorical\n",
      "[rule 0]: reported_event_totalsInferred nct_id from numerical as categorical\n",
      "[rule 0]: designsInferred id from numerical as categorical\n",
      "[rule 0]: designsInferred nct_id from numerical as categorical\n",
      "[rule 0]: designsInferred observational_model from text_embedded as categorical\n",
      "[rule 0]: conditions_studiesInferred id from numerical as categorical\n",
      "[rule 0]: conditions_studiesInferred nct_id from numerical as categorical\n",
      "[rule 0]: conditions_studiesInferred condition_id from numerical as categorical\n",
      "[rule 0]: drop_withdrawalsInferred id from numerical as categorical\n",
      "[rule 0]: drop_withdrawalsInferred nct_id from numerical as categorical\n",
      "[rule 0]: studiesInferred nct_id from numerical as categorical\n",
      "[rule 1]: studiesInferred number_of_arms from numerical as categorical\n",
      "[rule 1]: studiesInferred number_of_groups from numerical as categorical\n",
      "[rule 0]: studiesInferred baseline_type_units_analyzed from text_embedded as categorical\n",
      "[rule 0]: outcome_analysesInferred id from numerical as categorical\n",
      "[rule 0]: outcome_analysesInferred nct_id from numerical as categorical\n",
      "[rule 0]: outcome_analysesInferred outcome_id from numerical as categorical\n",
      "[rule 0]: outcome_analysesInferred param_type from text_embedded as categorical\n",
      "[rule 1]: outcome_analysesInferred p_value_modifier from text_embedded as categorical\n",
      "[rule 1]: outcome_analysesInferred ci_percent from numerical as categorical\n",
      "[rule 0]: sponsors_studiesInferred id from numerical as categorical\n",
      "[rule 0]: sponsors_studiesInferred nct_id from numerical as categorical\n",
      "[rule 0]: sponsors_studiesInferred sponsor_id from numerical as categorical\n",
      "[rule 0]: outcomesInferred id from numerical as categorical\n",
      "[rule 0]: outcomesInferred nct_id from numerical as categorical\n",
      "[rule 0]: outcomesInferred dispersion_type from text_embedded as categorical\n",
      "[rule 0]: outcomesInferred param_type from text_embedded as categorical\n",
      "[rule 0]: conditionsInferred condition_id from numerical as categorical\n",
      "[rule 0]: facilitiesInferred facility_id from numerical as categorical\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocess import infer_type_in_db\n",
    "col_type_dict = infer_type_in_db(db, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interventions.mesh_term: text_embedded, unique values: 3462/3462 Nan Value: 0/3462\n",
      "sponsors.name: text_embedded, unique values: 53241/53241 Nan Value: 0/53241\n",
      "eligibilities.minimum_age: text_embedded, unique values: 289/249730 Nan Value: 15682/249730\n",
      "eligibilities.maximum_age: text_embedded, unique values: 435/249730 Nan Value: 117182/249730\n",
      "eligibilities.population: text_embedded, unique values: 47240/249730 Nan Value: 200515/249730\n",
      "eligibilities.criteria: text_embedded, unique values: 247383/249730 Nan Value: 20/249730\n",
      "eligibilities.gender_description: text_embedded, unique values: 2447/249730 Nan Value: 246685/249730\n",
      "designs.masking_description: text_embedded, unique values: 9875/249093 Nan Value: 237703/249093\n",
      "designs.intervention_model_description: text_embedded, unique values: 19980/249093 Nan Value: 227583/249093\n",
      "drop_withdrawals.period: text_embedded, unique values: 7039/381199 Nan Value: 0/381199\n",
      "drop_withdrawals.reason: text_embedded, unique values: 22089/381199 Nan Value: 0/381199\n",
      "studies.target_duration: text_embedded, unique values: 124/249730 Nan Value: 246192/249730\n",
      "studies.acronym: text_embedded, unique values: 53088/249730 Nan Value: 184482/249730\n",
      "studies.baseline_population: text_embedded, unique values: 15707/249730 Nan Value: 231182/249730\n",
      "studies.brief_title: text_embedded, unique values: 248992/249730 Nan Value: 0/249730\n",
      "studies.official_title: text_embedded, unique values: 243352/249730 Nan Value: 5103/249730\n",
      "studies.source: text_embedded, unique values: 17308/249730 Nan Value: 0/249730\n",
      "studies.biospec_description: text_embedded, unique values: 7822/249730 Nan Value: 239591/249730\n",
      "studies.detailed_descriptions: text_embedded, unique values: 163478/249730 Nan Value: 85032/249730\n",
      "studies.brief_summaries: text_embedded, unique values: 248419/249730 Nan Value: 0/249730\n",
      "outcome_analyses.non_inferiority_description: text_embedded, unique values: 9343/225846 Nan Value: 199484/225846\n",
      "outcome_analyses.ci_upper_limit_na_comment: text_embedded, unique values: 19/225846 Nan Value: 225782/225846\n",
      "outcome_analyses.p_value_description: text_embedded, unique values: 15783/225846 Nan Value: 158749/225846\n",
      "outcome_analyses.method: text_embedded, unique values: 3340/225846 Nan Value: 30847/225846\n",
      "outcome_analyses.method_description: text_embedded, unique values: 10393/225846 Nan Value: 181810/225846\n",
      "outcome_analyses.estimate_description: text_embedded, unique values: 13121/225846 Nan Value: 181476/225846\n",
      "outcome_analyses.groups_description: text_embedded, unique values: 60426/225846 Nan Value: 90885/225846\n",
      "outcome_analyses.other_analysis_description: text_embedded, unique values: 920/225846 Nan Value: 224103/225846\n",
      "outcomes.title: text_embedded, unique values: 340156/411933 Nan Value: 0/411933\n",
      "outcomes.description: text_embedded, unique values: 311351/411933 Nan Value: 36134/411933\n",
      "outcomes.time_frame: text_embedded, unique values: 117763/411933 Nan Value: 59/411933\n",
      "outcomes.population: text_embedded, unique values: 125183/411933 Nan Value: 93581/411933\n",
      "outcomes.units: text_embedded, unique values: 32453/411933 Nan Value: 26110/411933\n",
      "outcomes.units_analyzed: text_embedded, unique values: 1625/411933 Nan Value: 403943/411933\n",
      "conditions.mesh_term: text_embedded, unique values: 3973/3973 Nan Value: 0/3973\n",
      "facilities.name: text_embedded, unique values: 453233/453233 Nan Value: 1/453233\n",
      "facilities.city: text_embedded, unique values: 28166/453233 Nan Value: 12/453233\n",
      "facilities.state: text_embedded, unique values: 7723/453233 Nan Value: 227304/453233\n",
      "facilities.zip: text_embedded, unique values: 48348/453233 Nan Value: 100020/453233\n",
      "facilities.country: text_embedded, unique values: 211/453233 Nan Value: 12/453233\n"
     ]
    }
   ],
   "source": [
    "# print text embedding type, profile\n",
    "for table, type_dict in col_type_dict.items():\n",
    "    for col_name, stype in type_dict.items():\n",
    "        if stype == stype.text_embedded:\n",
    "            unique_value = db.table_dict[table].df[col_name].unique()\n",
    "            n = len(unique_value)\n",
    "            nm = len(db.table_dict[table].df)\n",
    "            nan_num = db.table_dict[table].df[col_name].isnull().sum()\n",
    "            print(f\"{table}.{col_name}: {stype}, unique values: {n}/{nm} Nan Value: {nan_num}/{nm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the additional edges\n",
    "from utils.util import load_np_dict\n",
    "edge_dict = load_np_dict(\"./edges/rel-trail-edges.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pkey_fkey(col_to_stype: Dict[str, Any], table:Table) -> dict:\n",
    "    r\"\"\"Remove pkey, fkey columns since they will not be used as input feature.\"\"\"\n",
    "    if table.pkey_col is not None:\n",
    "        if table.pkey_col in col_to_stype:\n",
    "            col_to_stype.pop(table.pkey_col)\n",
    "    for fkey in table.fkey_col_to_pkey_table.keys():\n",
    "        if fkey in col_to_stype:\n",
    "            col_to_stype.pop(fkey)\n",
    "\n",
    "def to_unix_time(ser: pd.Series) -> np.ndarray:\n",
    "    r\"\"\"Converts a :class:`pandas.Timestamp` series to UNIX timestamp (in seconds).\"\"\"\n",
    "    assert ser.dtype in [np.dtype(\"datetime64[s]\"), np.dtype(\"datetime64[ns]\")]\n",
    "    unix_time = ser.astype(\"int64\").values\n",
    "    if ser.dtype == np.dtype(\"datetime64[ns]\"):\n",
    "        unix_time //= 10**9\n",
    "    return unix_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from torch_frame.config.text_embedder import TextEmbedderConfig\n",
    "from sentence_transformers import SentenceTransformer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class GloveTextEmbedding:\n",
    "    def __init__(self, device: Optional[torch.device\n",
    "                                       ] = None):\n",
    "        self.model = SentenceTransformer(\n",
    "            \"all-MiniLM-L12-v2\",\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "    def __call__(self, sentences: List[str]) -> Tensor:\n",
    "        return torch.from_numpy(self.model.encode(sentences))\n",
    "\n",
    "text_embedder_cfg = TextEmbedderConfig(\n",
    "    text_embedder=GloveTextEmbedding(device=device), batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> Compressing eligibilities text columns: ['minimum_age', 'maximum_age', 'population', 'gender_description']\n",
      "----> Compressing designs text columns: ['masking_description', 'intervention_model_description']\n"
     ]
    }
   ],
   "source": [
    "# preprocess the table, concatenate the columns which is text type\n",
    "#        /--- text_col_1 ---/ --- text_col_2 --- / --- text_col_3 --- / \n",
    "# row 1  /------- A   -----/ ------- B   -----  / -----   C  ------- /\n",
    "# -------> Generate a new TexT column\n",
    "# \"text_col_1 is A, text_col_2 is B, text_col_3 is C\"\n",
    "\n",
    "# Therefore, we only need to convert this text column to vector \n",
    "# and drop the original text columns\n",
    "# for saving memory and computation \n",
    "\n",
    "\n",
    "for table_name, type_dict in col_type_dict.items():\n",
    "    # collect the text columns\n",
    "    text_cols = [ col for col, stype in type_dict.items() if stype == stype.text_embedded]\n",
    "    compress_cols = []\n",
    "    # for long text, we still keep it as one column\n",
    "    for col in text_cols:\n",
    "        avg_word_count = db.table_dict[table_name].df[col].dropna().apply(lambda x: len(str(x).split())).mean()\n",
    "        if avg_word_count < 128: # a half of default max length of BERT Max length （256）\n",
    "            # remove the long text cols\n",
    "            compress_cols.append(col)\n",
    "          \n",
    "    \n",
    "    if len(compress_cols) <= 1:\n",
    "        # if only one text column, we do not need to compress\n",
    "        continue\n",
    "    \n",
    "    print(f\"----> Compressing {table_name} text columns: {compress_cols}\")\n",
    "    \n",
    "    df = db.table_dict[table_name].df\n",
    "    compress_text_df = df[compress_cols]\n",
    "    \n",
    "    def row_to_text(row):\n",
    "        if row.isna().all():\n",
    "            return None\n",
    "        tokens = [f\"{key} is {value}\" for key, value in row.dropna().items()]\n",
    "        return \", \".join(tokens)\n",
    "\n",
    "    text_list = compress_text_df.apply(row_to_text, axis=1).tolist()\n",
    "    \n",
    "    # drop the compressed columns\n",
    "    df.drop(columns=compress_cols, inplace=True)\n",
    "    df[\"text_compress\"] = text_list\n",
    "    \n",
    "    # update the type dict\n",
    "    for col in compress_cols:\n",
    "        type_dict.pop(col)\n",
    "    type_dict[\"text_compress\"] = stype.text_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interventions.mesh_term: text_embedded --> unique values: 3462/3462 || Nan Value: 0/3462\n",
      "sponsors.name: text_embedded --> unique values: 53241/53241 || Nan Value: 0/53241\n",
      "eligibilities.criteria: text_embedded --> unique values: 247383/249730 || Nan Value: 20/249730\n",
      "eligibilities.text_compress: text_embedded --> unique values: 54390/249730 || Nan Value: 6134/249730\n",
      "designs.text_compress: text_embedded --> unique values: 23381/249093 || Nan Value: 224148/249093\n",
      "drop_withdrawals.text_compress: text_embedded --> unique values: 47441/381199 || Nan Value: 0/381199\n",
      "studies.detailed_descriptions: text_embedded --> unique values: 163478/249730 || Nan Value: 85032/249730\n",
      "studies.text_compress: text_embedded --> unique values: 249662/249730 || Nan Value: 0/249730\n",
      "outcome_analyses.text_compress: text_embedded --> unique values: 98833/225846 || Nan Value: 3523/225846\n",
      "outcomes.text_compress: text_embedded --> unique values: 409051/411933 || Nan Value: 0/411933\n",
      "conditions.mesh_term: text_embedded --> unique values: 3973/3973 || Nan Value: 0/3973\n",
      "facilities.text_compress: text_embedded --> unique values: 453233/453233 || Nan Value: 0/453233\n"
     ]
    }
   ],
   "source": [
    "# print text embedding type\n",
    "for table, type_dict in col_type_dict.items():\n",
    "    for col_name, stype in type_dict.items():\n",
    "        if stype == stype.text_embedded:\n",
    "            unique_value = db.table_dict[table].df[col_name].unique()\n",
    "            n = len(unique_value)\n",
    "            nm = len(db.table_dict[table].df)\n",
    "            nan_num = db.table_dict[table].df[col_name].isnull().sum()\n",
    "            print(f\"{table}.{col_name}: {stype} --> unique values: {n}/{nm} || Nan Value: {nan_num}/{nm}\")\n",
    "        \n",
    "        # if stype == stype.categorical:\n",
    "        #     unique_value = db.table_dict[table].df[col_name].unique()\n",
    "        #     n = len(unique_value)\n",
    "        #     nm = len(db.table_dict[table].df)\n",
    "        #     print(f\"{table}.{col_name}: {stype}, unique values: {n}/{nm}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> Materialize interventions Tensor Frame\n",
      "-----> Materialize interventions_studies Tensor Frame\n",
      "-----> Materialize facilities_studies Tensor Frame\n",
      "-----> Materialize sponsors Tensor Frame\n",
      "-----> Materialize eligibilities Tensor Frame\n",
      "-----> Materialize reported_event_totals Tensor Frame\n",
      "-----> Materialize designs Tensor Frame\n",
      "-----> Materialize conditions_studies Tensor Frame\n",
      "-----> Materialize drop_withdrawals Tensor Frame\n",
      "-----> Materialize studies Tensor Frame\n",
      "-----> Materialize outcome_analyses Tensor Frame\n",
      "-----> Materialize sponsors_studies Tensor Frame\n",
      "-----> Materialize outcomes Tensor Frame\n",
      "-----> Materialize conditions Tensor Frame\n",
      "-----> Materialize facilities Tensor Frame\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start build graph\n",
    "cache_dir = \"./data/rel-trial-tensor-frame\"\n",
    "if cache_dir is not None:\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "data = HeteroData()\n",
    "col_stats_dict = {}\n",
    "for table_name, table in db.table_dict.items():\n",
    "    df = table.df\n",
    "    # (important for foreignKey value) Ensure the pkey is consecutive\n",
    "    if table.pkey_col is not None:\n",
    "        assert (df[table.pkey_col].values == np.arange(len(df))).all()\n",
    "    \n",
    "    col_to_stype = col_type_dict[table_name]\n",
    "    \n",
    "    # remove pkey, fkey\n",
    "    remove_pkey_fkey(col_to_stype, table)\n",
    "    \n",
    "    if len(col_to_stype) == 0:\n",
    "        # for example, relationship table which only contains pkey and fkey\n",
    "        raise KeyError(f\"{table_name} has no column to build graph\")\n",
    "    \n",
    "    path = (\n",
    "            None if cache_dir is None else os.path.join(cache_dir, f\"{table_name}.pt\")\n",
    "    )\n",
    "    \n",
    "    print(f\"-----> Materialize {table_name} Tensor Frame\")\n",
    "    dataset = Dataset(\n",
    "        df = df,\n",
    "        col_to_stype=col_to_stype,\n",
    "        col_to_text_embedder_cfg=text_embedder_cfg,\n",
    "    ).materialize(path=path)\n",
    "    \n",
    "    data[table_name].tf = dataset.tensor_frame\n",
    "    col_stats_dict[table_name] = dataset.col_stats\n",
    "    \n",
    "    # Add time attribute\n",
    "    if table.time_col is not None:\n",
    "        data[table_name].time = torch.from_numpy(\n",
    "            to_unix_time(df[table.time_col])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache the col_type_dict\n",
    "import pickle\n",
    "with open(f\"{cache_dir}/col_type_dict.pkl\", \"wb\") as f:\n",
    "    pickle.dump(col_type_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
