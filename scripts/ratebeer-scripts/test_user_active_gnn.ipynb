{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lingze/embedding_fusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import torch\n",
    "import math\n",
    "import argparse\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch.nn import L1Loss, BCEWithLogitsLoss\n",
    "from sklearn.metrics import mean_absolute_error, roc_auc_score\n",
    "from relbench.base import TaskType\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "from utils.util import load_col_types\n",
    "from utils.resource import get_text_embedder_cfg\n",
    "from utils.builder import build_pyg_hetero_graph\n",
    "from utils.data import DatabaseFactory\n",
    "from utils.sample import get_node_train_table_input_with_sample\n",
    "from model import HeteroGCN, HeteroGAT, HGT\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cache_dir = \"/home/lingze/.cache/relbench/ratebeer\"\n",
    "cache_dir = \"./data/ratebeer-tensor-frame\"\n",
    "db_name = \"ratebeer\"\n",
    "task_name = \"place-positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/ratebeer/db...\n",
      "Done in 0.74 seconds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db = DatabaseFactory.get_db(\n",
    "    db_name, cache_dir=data_cache_dir\n",
    ")\n",
    "\n",
    "dataset = DatabaseFactory.get_dataset(\n",
    "    db_name, cache_dir = data_cache_dir\n",
    ")\n",
    "\n",
    "task = DatabaseFactory.get_task(\n",
    "    db_name, task_name, dataset\n",
    ")\n",
    "\n",
    "col_type_dict = load_col_types(\n",
    "    cache_path=cache_dir,\n",
    "    file_name = \"col_type_dict.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> Materialize favorites Tensor Frame\n",
      "-----> Materialize beers Tensor Frame\n",
      "-----> Materialize places Tensor Frame\n",
      "-----> Materialize availability Tensor Frame\n",
      "-----> Materialize place_ratings Tensor Frame\n",
      "-----> Materialize beer_ratings Tensor Frame\n",
      "-----> Materialize countries Tensor Frame\n",
      "-----> Materialize brewers Tensor Frame\n",
      "-----> Materialize users Tensor Frame\n"
     ]
    }
   ],
   "source": [
    "data, col_stats_dict = build_pyg_hetero_graph(\n",
    "    db,\n",
    "    col_type_dict,\n",
    "    get_text_embedder_cfg(device=\"cpu\"),\n",
    "    cache_dir=cache_dir,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_ratio = 1\n",
    "test_ratio = 1\n",
    "batch_size = 256\n",
    "num_neighbors = [128, 64]\n",
    "\n",
    "channels = 128\n",
    "out_channels = 1\n",
    "norm = \"layer_norm\"\n",
    "aggr = \"sum\"\n",
    "edge_aggr = \"sum\"\n",
    "dropout = 0.3\n",
    "num_layers = 2\n",
    "heads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_loader_dict: Dict[str, NeighborLoader] = {}\n",
    "for split, sample_ratio, table in [\n",
    "    (\"train\", 1, task.get_table(\"train\")),\n",
    "    (\"valid\", validation_ratio, task.get_table(\"val\")),\n",
    "    (\"test\", test_ratio, task.get_table(\"test\", mask_input_cols=False)),\n",
    "]:\n",
    "\n",
    "    _, table_input = get_node_train_table_input_with_sample(\n",
    "        table=table,\n",
    "        task=task,\n",
    "        sample_ratio=sample_ratio,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    data_loader_dict[split] = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        time_attr=\"time\",\n",
    "        input_nodes=table_input.nodes,\n",
    "        input_time=table_input.time,\n",
    "        transform=table_input.transform,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=split == \"train\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = HeteroGCN(\n",
    "    data,\n",
    "    col_stats_dict,\n",
    "    channels=channels,\n",
    "    out_channels=out_channels,\n",
    "    num_layers = num_layers,\n",
    "    aggr = aggr,\n",
    "    edge_aggr = edge_aggr,\n",
    "    dropout = dropout,\n",
    "    norm = norm,\n",
    ")\n",
    "\n",
    "# net = HeteroGAT(\n",
    "#     data,\n",
    "#     col_stats_dict,\n",
    "#     channels=channels,\n",
    "#     out_channels=out_channels,\n",
    "#     num_layers = num_layers,\n",
    "#     aggr = aggr,\n",
    "#     edge_aggr = edge_aggr,\n",
    "#     dropout = dropout,\n",
    "#     norm = norm,\n",
    "# )\n",
    "\n",
    "# net =  net = HGT(\n",
    "#         data,\n",
    "#         col_stats_dict,\n",
    "#         channels=channels,\n",
    "#         out_channels=out_channels,\n",
    "#         num_layers=num_layers,\n",
    "#         aggr=aggr,\n",
    "#         edge_aggr=edge_aggr,\n",
    "#         dropout=dropout,\n",
    "#         norm=norm,\n",
    "#         heads=heads,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_regression = task.task_type == TaskType.REGRESSION\n",
    "\n",
    "\n",
    "def deactivate_dropout(net: torch.nn.Module):\n",
    "    \"\"\" Deactivate dropout layers in the model. for regression task\n",
    "    \"\"\"\n",
    "    deactive_nn_instances = (\n",
    "        torch.nn.Dropout, torch.nn.Dropout2d, torch.nn.Dropout3d)\n",
    "    for module in net.modules():\n",
    "        if isinstance(module, deactive_nn_instances):\n",
    "            module.eval()\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = False\n",
    "    return net\n",
    "net = deactivate_dropout(net) if is_regression else net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = L1Loss() if is_regression else BCEWithLogitsLoss()\n",
    "evaluate_metric_func = mean_absolute_error if is_regression else roc_auc_score\n",
    "higher_is_better = False if is_regression else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net: torch.nn.Module, loader: torch.utils.data.DataLoader, entity_table: str, early_stop: int = -1, is_regression: bool = False):\n",
    "    pred_list = []\n",
    "    y_list = []\n",
    "    early_stop = early_stop if early_stop > 0 else len(loader.dataset)\n",
    "\n",
    "    if not is_regression:\n",
    "        net.eval()\n",
    "\n",
    "    for idx, batch in tqdm(enumerate(loader), total=len(loader), leave=False, desc=\"Testing\"):\n",
    "        with torch.no_grad():\n",
    "            batch = batch.to(device)\n",
    "            y = batch[entity_table].y.float()\n",
    "            pred = net(batch, entity_table)\n",
    "            pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "            pred_list.append(pred.detach().cpu())\n",
    "            y_list.append(y.detach().cpu())\n",
    "        if idx > early_stop:\n",
    "            break\n",
    "\n",
    "    pred_list = pred_logits = torch.cat(pred_list, dim=0)\n",
    "    pred_list = torch.sigmoid(pred_list).numpy()\n",
    "    y_list = torch.cat(y_list, dim=0).numpy()\n",
    "    return pred_logits.numpy(), pred_list,  y_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "num_epochs = 500\n",
    "early_stop_threshold = 2\n",
    "max_round_epoch = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, net.parameters()), lr=lr\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init training variables\n",
    "net.to(device)\n",
    "patience = 0\n",
    "best_epoch = 0\n",
    "best_val_metric = -math.inf if higher_is_better else math.inf\n",
    "best_model_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 0 => Train Loss: 0.715412, Val roc_auc_score Metric: 0.638780 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.651510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 1 => Train Loss: 0.653358, Val roc_auc_score Metric: 0.642663 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.669429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 2 => Train Loss: 0.642796, Val roc_auc_score Metric: 0.665023 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.684276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 3 => Train Loss: 0.639465, Val roc_auc_score Metric: 0.711785 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.722610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 4 => Train Loss: 0.618940, Val roc_auc_score Metric: 0.749072 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.753519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 5 => Train Loss: 0.579253, Val roc_auc_score Metric: 0.763426 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.761799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 6 => Train Loss: 0.567418, Val roc_auc_score Metric: 0.779911 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.769194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 7 => Train Loss: 0.553163, Val roc_auc_score Metric: 0.807928 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.784731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 8 => Train Loss: 0.519167, Val roc_auc_score Metric: 0.823271 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.789309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 9 => Train Loss: 0.485041, Val roc_auc_score Metric: 0.835955 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.793740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 10 => Train Loss: 0.497251, Val roc_auc_score Metric: 0.835817 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 11 => Train Loss: 0.453633, Val roc_auc_score Metric: 0.845749 \t1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.808568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 12 => Train Loss: 0.481697, Val roc_auc_score Metric: 0.838476 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 13 => Train Loss: 0.455922, Val roc_auc_score Metric: 0.828255 \t1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 14 => Train Loss: 0.452501, Val roc_auc_score Metric: 0.848882 \t2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores => Test roc_auc_score Metric: 0.814017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 15 => Train Loss: 0.451969, Val roc_auc_score Metric: 0.846257 \t0/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 16 => Train Loss: 0.439286, Val roc_auc_score Metric: 0.847974 \t1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Epcoh: 17 => Train Loss: 0.449091, Val roc_auc_score Metric: 0.831111 \t2/2\n",
      "Early stopping at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_accum = count_accum = 0\n",
    "    net.train()\n",
    "    for idx, batch in tqdm(enumerate(data_loader_dict[\"train\"]),\n",
    "                           leave=False,\n",
    "                           total=len(data_loader_dict[\"train\"]),\n",
    "                           desc=\"Training\"):\n",
    "        if idx > max_round_epoch:\n",
    "            break\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "        y = batch[task.entity_table].y.float()\n",
    "        pred = net(batch, task.entity_table)\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_accum += loss.item()\n",
    "        count_accum += 1\n",
    "    train_loss = loss_accum / count_accum\n",
    "    val_logits, _, val_pred_hat = test(\n",
    "        net, data_loader_dict[\"valid\"], task.entity_table, early_stop=-1, is_regression=is_regression\n",
    "    )\n",
    "    val_metric = evaluate_metric_func(val_pred_hat, val_logits)\n",
    "    print(\n",
    "        f\"==> Epcoh: {epoch} => Train Loss: {train_loss:.6f}, Val {evaluate_metric_func.__name__} Metric: {val_metric:.6f} \\t{patience}/{early_stop_threshold}\")\n",
    "\n",
    "    if (higher_is_better and val_metric > best_val_metric) or \\\n",
    "       (not higher_is_better and val_metric < best_val_metric):\n",
    "        best_val_metric = val_metric\n",
    "        best_epoch = epoch\n",
    "        best_model_state = copy.deepcopy(net.state_dict())\n",
    "        patience = 0\n",
    "\n",
    "        if True:\n",
    "            test_logits, _, test_pred_hat = test(\n",
    "                net, data_loader_dict[\"test\"], task.entity_table, is_regression=is_regression)\n",
    "            test_metric = evaluate_metric_func(test_pred_hat, test_logits)\n",
    "\n",
    "            print(\n",
    "                f\"Update the best scores => Test {evaluate_metric_func.__name__} Metric: {test_metric:.6f}\")\n",
    "        else:\n",
    "            print(\n",
    "                f\"Update the best scores \\t \"\n",
    "            )\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience > early_stop_threshold:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(best_model_state)\n",
    "table = task.get_table(\"test\", mask_input_cols=False)\n",
    "_, table_input = get_node_train_table_input_with_sample(\n",
    "    table=table,\n",
    "    task=task,\n",
    "    sample_ratio=1,\n",
    "    shuffle=False,\n",
    ")\n",
    "loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=num_neighbors,\n",
    "    time_attr=\"time\",\n",
    "    input_nodes=table_input.nodes,\n",
    "    input_time=table_input.time,\n",
    "    transform=table_input.transform,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test roc_auc_score Metric: 0.814014\n"
     ]
    }
   ],
   "source": [
    "test_logits, _, test_pred_hat = test(\n",
    "    net, loader, task.entity_table, is_regression=is_regression)\n",
    "test_metric = evaluate_metric_func(test_pred_hat, test_logits)\n",
    "print(\n",
    "    f\"Test {evaluate_metric_func.__name__} Metric: {test_metric:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
