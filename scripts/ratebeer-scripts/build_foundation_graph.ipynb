{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lingze/embedding_fusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "from relbench.datasets import get_dataset\n",
    "\n",
    "from utils.data import DatabaseFactory\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = \"/home/lingze/.cache/relbench/ratebeer\"\n",
    "dataset = DatabaseFactory.get_dataset(\"ratebeer\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/ratebeer/db...\n",
      "Done in 0.84 seconds.\n"
     ]
    }
   ],
   "source": [
    "db = DatabaseFactory.get_db(\"ratebeer\", cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rule 0]: favorites Inferred favorite_id from numerical as categorical\n",
      "[rule 0]: favorites Inferred user_id from numerical as categorical\n",
      "[rule 0]: favorites Inferred beer_id from numerical as categorical\n",
      "[rule 0]: favorites Inferred list_id from numerical as categorical\n",
      "[rule 0]: beers Inferred beer_id from numerical as categorical\n",
      "[rule 0]: beers Inferred brewer_id from numerical as categorical\n",
      "[rule 0]: beers Inferred style_id from numerical as categorical\n",
      "[rule 1]: beers Inferred view_count from numerical as categorical\n",
      "[rule 1]: beers Inferred last_9m_count from numerical as categorical\n",
      "[rule 0]: places Inferred place_id from numerical as categorical\n",
      "[rule 0]: places Inferred state_id from numerical as categorical\n",
      "[rule 0]: places Inferred country_id from numerical as categorical\n",
      "[rule 1]: places Inferred has_cigars from numerical as categorical\n",
      "[rule 1]: places Inferred takes_reservations from numerical as categorical\n",
      "[rule 1]: places Inferred has_games from numerical as categorical\n",
      "[rule 1]: places Inferred percentile from numerical as categorical\n",
      "[rule 0]: availability Inferred avail_id from numerical as categorical\n",
      "[rule 0]: availability Inferred beer_id from numerical as categorical\n",
      "[rule 0]: availability Inferred place_id from numerical as categorical\n",
      "[rule 0]: availability Inferred postal_code from text_embedded as categorical\n",
      "[rule 0]: availability Inferred state_id from numerical as categorical\n",
      "[rule 0]: availability Inferred country_id from numerical as categorical\n",
      "[rule 0]: availability Inferred user_id from numerical as categorical\n",
      "[rule 0]: place_ratings Inferred rating_id from numerical as categorical\n",
      "[rule 0]: place_ratings Inferred user_id from numerical as categorical\n",
      "[rule 0]: place_ratings Inferred place_id from numerical as categorical\n",
      "[rule 0]: place_ratingsInferred ambiance_score from categorical as numerical\n",
      "[rule 1]: place_ratings Inferred ambiance_score from numerical as categorical\n",
      "[rule 0]: place_ratingsInferred service_score from categorical as numerical\n",
      "[rule 1]: place_ratings Inferred service_score from numerical as categorical\n",
      "[rule 0]: place_ratingsInferred selection_score from categorical as numerical\n",
      "[rule 1]: place_ratings Inferred selection_score from numerical as categorical\n",
      "[rule 0]: place_ratingsInferred food_score from categorical as numerical\n",
      "[rule 1]: place_ratings Inferred food_score from numerical as categorical\n",
      "[rule 0]: place_ratingsInferred value from categorical as numerical\n",
      "[rule 1]: place_ratings Inferred value from numerical as categorical\n",
      "[rule 1]: place_ratings Inferred total_score from numerical as categorical\n",
      "[rule 0]: beer_ratings Inferred rating_id from numerical as categorical\n",
      "[rule 0]: beer_ratings Inferred user_id from numerical as categorical\n",
      "[rule 0]: beer_ratings Inferred beer_id from numerical as categorical\n",
      "[rule 0]: beer_ratingsInferred aroma_score from categorical as numerical\n",
      "[rule 1]: beer_ratings Inferred aroma_score from numerical as categorical\n",
      "[rule 0]: beer_ratingsInferred flavor_score from categorical as numerical\n",
      "[rule 1]: beer_ratings Inferred flavor_score from numerical as categorical\n",
      "[rule 0]: beer_ratingsInferred mouthfeel_score from categorical as numerical\n",
      "[rule 1]: beer_ratings Inferred mouthfeel_score from numerical as categorical\n",
      "[rule 0]: beer_ratingsInferred appearance_score from categorical as numerical\n",
      "[rule 1]: beer_ratings Inferred appearance_score from numerical as categorical\n",
      "[rule 0]: beer_ratingsInferred overall_score from categorical as numerical\n",
      "[rule 1]: beer_ratings Inferred overall_score from numerical as categorical\n",
      "[rule 1]: beer_ratings Inferred total_score from numerical as categorical\n",
      "[rule 0]: countries Inferred country_id from numerical as categorical\n",
      "[rule 0]: countries Inferred code from text_embedded as categorical\n",
      "[rule 0]: brewers Inferred brewer_id from numerical as categorical\n",
      "[rule 0]: brewers Inferred state_id from numerical as categorical\n",
      "[rule 0]: brewers Inferred country_id from numerical as categorical\n",
      "[rule 0]: brewers Inferred beer_jobber_id from numerical as categorical\n",
      "[rule 0]: brewers Inferred metro_id from numerical as categorical\n",
      "[rule 0]: users Inferred user_id from numerical as categorical\n",
      "[rule 1]: users Inferred max_beer_rating from numerical as categorical\n",
      "[rule 1]: users Inferred min_beer_rating from numerical as categorical\n",
      "[rule 1]: users Inferred favorite_count from numerical as categorical\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocess import infer_type_in_db\n",
    "\n",
    "col_type_dict = infer_type_in_db(db, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> No need to compress favorites text columns: []\n",
      "----> No need to compress beers text columns: []\n",
      "----> No need to compress places text columns: []\n",
      "----> No need to compress availability text columns: []\n",
      "----> No need to compress place_ratings text columns: []\n",
      "----> No need to compress beer_ratings text columns: []\n",
      "----> No need to compress countries text columns: []\n",
      "----> No need to compress brewers text columns: []\n",
      "----> No need to compress users text columns: []\n"
     ]
    }
   ],
   "source": [
    "# preprocess the table, concatenate the columns which is text type\n",
    "#        /--- text_col_1 ---/ --- text_col_2 --- / --- text_col_3 --- / \n",
    "# row 1  /------- A   -----/ ------- B   -----  / -----   C  ------- /\n",
    "# -------> Generate a new TexT column\n",
    "# \"text_col_1 is A, text_col_2 is B, text_col_3 is C\"\n",
    "\n",
    "# Therefore, we only need to convert this text column to vector \n",
    "# and drop the original text columns\n",
    "# for saving memory and computation \n",
    "from torch_frame import stype\n",
    "\n",
    "for table_name, type_dict in col_type_dict.items():\n",
    "    # collect the text columns\n",
    "    text_cols = [ col for col, stype in type_dict.items() if stype == stype.text_embedded]\n",
    "    compress_cols = []\n",
    "    # for long text, we still keep it as one column\n",
    "    for col in text_cols:\n",
    "        avg_word_count = db.table_dict[table_name].df[col].dropna().apply(lambda x: len(str(x).split())).mean()\n",
    "        if avg_word_count < 128: # a half of default max length of BERT Max length （256）\n",
    "            # remove the long text cols\n",
    "            compress_cols.append(col)\n",
    "          \n",
    "    \n",
    "    if len(compress_cols) <= 1:\n",
    "        # if only one text column, we do not need to compress\n",
    "        print(f\"----> No need to compress {table_name} text columns: {compress_cols}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"----> Compressing {table_name} text columns: {compress_cols}\")\n",
    "    \n",
    "    df = db.table_dict[table_name].df\n",
    "    compress_text_df = df[compress_cols]\n",
    "    \n",
    "    def row_to_text(row):\n",
    "        if row.isna().all():\n",
    "            return None\n",
    "        tokens = [f\"{key} is {value}\" for key, value in row.dropna().items()]\n",
    "        return \", \".join(tokens)\n",
    "\n",
    "    text_list = compress_text_df.apply(row_to_text, axis=1).tolist()\n",
    "    \n",
    "    # drop the compressed columns\n",
    "    df.drop(columns=compress_cols, inplace=True)\n",
    "    df[\"text_compress\"] = text_list\n",
    "    \n",
    "    # update the type dict\n",
    "    for col in compress_cols:\n",
    "        type_dict.pop(col)\n",
    "    type_dict[\"text_compress\"] = stype.text_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.resource import get_text_embedder_cfg\n",
    "text_embedder_cfg = get_text_embedder_cfg(\n",
    "    # model_name = \"sentence-transformers/average_word_embeddings_glove.6B.300d\", \n",
    "    model_name = \"all-MiniLM-L12-v2\",\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> Materialize favorites Tensor Frame\n",
      "-----> Materialize beers Tensor Frame\n",
      "-----> Materialize places Tensor Frame\n",
      "-----> Materialize availability Tensor Frame\n",
      "-----> Materialize place_ratings Tensor Frame\n",
      "-----> Materialize beer_ratings Tensor Frame\n",
      "-----> Materialize countries Tensor Frame\n",
      "-----> Materialize brewers Tensor Frame\n",
      "-----> Materialize users Tensor Frame\n"
     ]
    }
   ],
   "source": [
    "# materialize the tensor_frame \n",
    "from utils.builder import build_pyg_hetero_graph\n",
    "cache_dir = \"./data/ratebeer-tensor-frame\"\n",
    "data, col_stats_dict = build_pyg_hetero_graph(\n",
    "    db,\n",
    "    col_type_dict,\n",
    "    text_embedder_cfg,\n",
    "    cache_dir,\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the col_type_dict\n",
    "with open(os.path.join(cache_dir, \"col_type_dict.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(col_type_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
