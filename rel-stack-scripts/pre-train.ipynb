{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lingze/embedding_fusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from tqdm import tqdm\n",
    "from utils.data import StackDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "device = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/stack/db...\n",
      "Done in 10.11 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = StackDataset(cache_dir=\"/home/lingze/.cache/relbench/stack\")\n",
    "db = dataset.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = \"./data/stack-tensor-frame/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [NOTE]: the dataset has been materialized\n",
    "\n",
    "# get infer_type in cache\n",
    "type_path = os.path.join(cache_path,\"col_type_dict.pkl\")\n",
    "col_type_dict = pickle.load(open(type_path, \"rb\"))\n",
    "len(col_type_dict)\n",
    "\n",
    "# add \"compress_text\" in each table in case \n",
    "for table_name, table in db.table_dict.items():\n",
    "    table.df[\"text_compress\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from utils.resource import get_text_embedder_cfg\n",
    "text_embedder_cfg = get_text_embedder_cfg(\n",
    "    model_name = \"sentence-transformers/average_word_embeddings_glove.6B.300d\", \n",
    "    device = torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> Materialize tags Tensor Frame\n",
      "-----> Materialize postHistory Tensor Frame\n",
      "-----> Materialize comments Tensor Frame\n",
      "-----> Materialize badges Tensor Frame\n",
      "-----> Build edge between posts and tags\n",
      "-----> Materialize users Tensor Frame\n",
      "-----> Materialize postLinks Tensor Frame\n",
      "-----> Materialize votes Tensor Frame\n",
      "-----> Materialize posts Tensor Frame\n"
     ]
    }
   ],
   "source": [
    "from utils.builder import build_pyg_hetero_graph\n",
    "data, col_stats_dict = build_pyg_hetero_graph(\n",
    "    db,\n",
    "    col_type_dict,\n",
    "    text_embedder_cfg,\n",
    "    cache_path,\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new edges:\n",
    "from utils.util import load_np_dict\n",
    "from torch_geometric.utils import sort_edge_index\n",
    "edge_dict = load_np_dict(\"./edges/rel-stack-edges.npz\")\n",
    "\n",
    "for edge_name, edge_np in edge_dict.items():\n",
    "    src_table, dst_table = edge_name.split('-')[0], edge_name.split('-')[1]\n",
    "    edge_index = torch.from_numpy(edge_np.astype(int)).t()\n",
    "    # [2, edge_num]\n",
    "    edge_type = (src_table, f\"appendix\", dst_table)\n",
    "    data[edge_type].edge_index = sort_edge_index(edge_index)\n",
    "data.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['tags', 'badges', 'users', 'posts'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the pre-extracted sample\n",
    "from utils.util import load_np_dict\n",
    "sample_dict = load_np_dict(\"./samples/rel-stack-samples.npz\")\n",
    "sample_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relbench.tasks import get_task\n",
    "from relbench.modeling.graph import get_node_train_table_input\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from relbench.base import BaseTask\n",
    "from model.base import CompositeModel, FeatureEncodingPart, NodeRepresentationPart\n",
    "from relbench.modeling.nn import HeteroTemporalEncoder\n",
    "# start to fine-train on the task a\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import math\n",
    "import copy\n",
    "from relbench.modeling.utils import to_unix_time\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from relbench.base import Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neighborsample_batch(\n",
    "    db: Database,\n",
    "    entity_table: str,\n",
    "    node_idxs: np.ndarray,\n",
    "    num_neighbors: List[int] = [64,64],\n",
    "):\n",
    "    # node_idxs: [n]\n",
    "    nodes = (entity_table, torch.from_numpy(node_idxs))\n",
    "    n = node_idxs.shape[0]\n",
    "    input_time = torch.from_numpy(\n",
    "        to_unix_time(pd.Series([db.max_timestamp] * n)))\n",
    "\n",
    "    if db.table_dict[entity_table].time_col:\n",
    "        time_col = db.table_dict[entity_table].time_col\n",
    "        time_values = db.table_dict[entity_table].df[time_col].loc[node_idxs.tolist(\n",
    "        )]\n",
    "        input_time = torch.from_numpy(to_unix_time(time_values))\n",
    "\n",
    "    loader = NeighborLoader(\n",
    "        data,\n",
    "        num_neighbors=num_neighbors,\n",
    "        input_nodes=nodes,\n",
    "        time_attr = \"time\",\n",
    "        input_time=input_time,\n",
    "        batch_size=n,\n",
    "        temporal_strategy=\"uniform\",\n",
    "        shuffle=False,\n",
    "        disjoint=True,\n",
    "        num_workers=0,\n",
    "        persistent_workers=False,\n",
    "    )\n",
    "    return next(iter(loader))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct bottom model\n",
    "channels = 128\n",
    "temporal_encoder = HeteroTemporalEncoder(\n",
    "    node_types=[\n",
    "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
    "            ],\n",
    "    channels=channels,\n",
    ")\n",
    "\n",
    "feat_encoder = FeatureEncodingPart(\n",
    "    data=data,\n",
    "    node_to_col_stats=col_stats_dict,\n",
    "    channels=channels\n",
    ")\n",
    "\n",
    "node_encoder = NodeRepresentationPart(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    num_layers=1,\n",
    "    normalization=\"layer_norm\",\n",
    "    dropout_prob=0.4\n",
    ")\n",
    "\n",
    "\n",
    "net = CompositeModel(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    out_channels=1,\n",
    "    dropout=0.4,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    "    num_layer=2,\n",
    "    feature_encoder=feat_encoder,\n",
    "    node_encoder=node_encoder,\n",
    "    temporal_encoder=temporal_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.utils import InfoNCE\n",
    "import time\n",
    "import random\n",
    "lr = 0.0005\n",
    "negative_sample_pool_size = 512\n",
    "temprature = 0.01\n",
    "net.reset_parameters()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = lr)\n",
    "epoches = 300\n",
    "batch_size = 128\n",
    "max_steps_in_epoch = 10\n",
    "negative_num = 20\n",
    "loss_fn = InfoNCE(temperature=temprature, negative_mode='paired', reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.to(device)\n",
    "best_loss = math.inf\n",
    "best_state = None\n",
    "patience = 0\n",
    "early_stop = 20\n",
    "n_tables = len(sample_dict)\n",
    "tables = list(sample_dict.keys())\n",
    "for epoch in range(1, epoches + 1):\n",
    "    net.train()\n",
    "    ave_loss = 0\n",
    "    print(\"*\"*30 + f\"<Epoch: {epoch:02d}>\" + \"*\"*30)\n",
    "    random.shuffle(tables)\n",
    "    for sample_table in tables:\n",
    "        \n",
    "        sample_np = sample_dict[sample_table]\n",
    "        loss_accum = count_accum = 0\n",
    "        shuffle_sample_np = sample_np[np.random.permutation(len(sample_np))]\n",
    "        anchor_nodes_np = shuffle_sample_np[:, 0]\n",
    "        positive_pool_np = shuffle_sample_np[:, 1:]\n",
    "        # choose the positive samples\n",
    "        n = sample_np.shape[0]\n",
    "\n",
    "        m = len(db.table_dict[sample_table].df)\n",
    "        now = time.time()\n",
    "        cnt = 0\n",
    "        for batch_idx in tqdm(range(0, n, batch_size), leave=False):\n",
    "            cnt += 1\n",
    "            if cnt > max_steps_in_epoch:\n",
    "                break\n",
    "            anchor_nodes = anchor_nodes_np[batch_idx:batch_idx+batch_size]\n",
    "            positive_pool_batch_np = positive_pool_np[batch_idx:batch_idx+batch_size]\n",
    "            positive_nodes = []\n",
    "            # random select the positive samples\n",
    "            for row in positive_pool_batch_np:\n",
    "                valid = row[row != -1]\n",
    "                random_choice = np.random.choice(valid, 1)[0]\n",
    "                positive_nodes.append(random_choice)\n",
    "\n",
    "            positive_nodes = np.array(positive_nodes)\n",
    "            B = positive_nodes.size\n",
    "            # random select the negative sample, negative ratio is 1:20\n",
    "            # for one batch, we still extract batch_size negative samples\n",
    "            # for each positive-negative pair, we extract 20 from this 256 batch as negative samples\n",
    "            excluded = set(positive_nodes.tolist()).union(\n",
    "                set(anchor_nodes.tolist()))\n",
    "            negative_candidates = list(set(range(m)) - excluded)\n",
    "            # print(negative_candidates)\n",
    "\n",
    "            sample_size = min(negative_sample_pool_size,\n",
    "                              len(negative_candidates))\n",
    "\n",
    "            negative_nodes = np.random.choice(\n",
    "                negative_candidates, size=sample_size, replace=True)\n",
    "            # [batch_size]\n",
    "            # print(negative_nodes.shape)\n",
    "            # print(B)\n",
    "            # neighbor hood loader\n",
    "            anchor_nodes_batch = neighborsample_batch(\n",
    "                db, sample_table, anchor_nodes)\n",
    "            positive_nodes_batch = neighborsample_batch(\n",
    "                db, sample_table, positive_nodes)\n",
    "            negative_nodes_batch = neighborsample_batch(\n",
    "                db, sample_table, negative_nodes)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            anchor_nodes_batch, positive_nodes_batch, negative_nodes_batch = \\\n",
    "                anchor_nodes_batch.to(device), positive_nodes_batch.to(\n",
    "                    device), negative_nodes_batch.to(device)\n",
    "\n",
    "            anchor_nodes_embedding = net.get_node_embedding(\n",
    "                anchor_nodes_batch, sample_table)[sample_table][:B]\n",
    "            positive_nodes_embedding = net.get_node_embedding(\n",
    "                positive_nodes_batch, sample_table)[sample_table][:B]\n",
    "            negative_nodes_embedding = net.get_node_embedding(\n",
    "                negative_nodes_batch, sample_table)[sample_table][:sample_size]\n",
    "\n",
    "            # negative_nodes_embedding = net.get_node_embedding(negative_nodes_batch, sample_table)[sample_table][:B]\n",
    "            # [B, D]\n",
    "\n",
    "            negative_indices = torch.stack([torch.randperm(sample_size)[\n",
    "                                           :negative_num] for _ in range(B)]).to(device)\n",
    "            negative_nodes_embedding = negative_nodes_embedding[negative_indices]\n",
    "            # [B, negative_num, D]\n",
    "\n",
    "            loss = loss_fn(anchor_nodes_embedding,\n",
    "                           positive_nodes_embedding, negative_nodes_embedding)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_accum += loss.detach().item() * B\n",
    "            count_accum += B\n",
    "        \n",
    "        end = time.time()\n",
    "        train_loss = loss_accum / count_accum\n",
    "        ave_loss += train_loss\n",
    "        mins, secs = divmod(end - now, 60)\n",
    "        print(\n",
    "            f\"====> In {sample_table}, Train loss: {train_loss} Count accum :{count_accum}, Cost Time {mins:.0f}m {secs:.0f}s\")\n",
    "\n",
    "    ave_loss /= n_tables\n",
    "    if ave_loss < best_loss:\n",
    "        best_loss = ave_loss\n",
    "        best_state = copy.deepcopy(net.state_dict())\n",
    "        print(f\"Save best model at epoch {epoch} with loss {ave_loss}\")\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= early_stop:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-trained state\n",
    "# record\n",
    "pre_trained_state = copy.deepcopy(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "torch.save(pre_trained_state, \"./static/rel-stack-pre-trained-channel128-ep100.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "torch.save(best_state, \"./static/rel-stack-pre-trained-channel128-ep100-best-state.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
