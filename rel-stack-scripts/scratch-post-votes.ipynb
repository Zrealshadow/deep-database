{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lingze/embedding_fusion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from tqdm import tqdm\n",
    "from utils.data import StackDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/stack/db...\n",
      "Done in 9.69 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = StackDataset(cache_dir=\"/home/lingze/.cache/relbench/stack\")\n",
    "db = dataset.get_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = \"./data/stack-tensor-frame/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [NOTE]: the dataset has been materialized\n",
    "\n",
    "# get infer_type in cache\n",
    "type_path = os.path.join(cache_path,\"col_type_dict.pkl\")\n",
    "col_type_dict = pickle.load(open(type_path, \"rb\"))\n",
    "len(col_type_dict)\n",
    "\n",
    "# add \"compress_text\" in each table in case \n",
    "for table_name, table in db.table_dict.items():\n",
    "    table.df[\"text_compress\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/anaconda3/envs/deepdb/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from utils.resource import get_text_embedder_cfg\n",
    "text_embedder_cfg = get_text_embedder_cfg(\n",
    "    model_name = \"sentence-transformers/average_word_embeddings_glove.6B.300d\", \n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----> Materialize tags Tensor Frame\n",
      "-----> Materialize postHistory Tensor Frame\n",
      "-----> Materialize comments Tensor Frame\n",
      "-----> Materialize badges Tensor Frame\n",
      "-----> Build edge between posts and tags\n",
      "-----> Materialize users Tensor Frame\n",
      "-----> Materialize postLinks Tensor Frame\n",
      "-----> Materialize votes Tensor Frame\n",
      "-----> Materialize posts Tensor Frame\n"
     ]
    }
   ],
   "source": [
    "from utils.builder import build_pyg_hetero_graph\n",
    "data, col_stats_dict = build_pyg_hetero_graph(\n",
    "    db,\n",
    "    col_type_dict,\n",
    "    text_embedder_cfg,\n",
    "    cache_path,\n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relbench.tasks import get_task\n",
    "from relbench.modeling.graph import get_node_train_table_input\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from relbench.base import BaseTask\n",
    "from model.base import CompositeModel, FeatureEncodingPart, NodeRepresentationPart\n",
    "from relbench.modeling.nn import HeteroTemporalEncoder\n",
    "# start to fine-train on the task a\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import math\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_a = get_task(\"rel-stack\", \"post-votes\", download = True)\n",
    "entity_table = task_a.entity_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_loader_dict(task: BaseTask, data:HeteroData) -> dict:\n",
    "    loader_dict = {}\n",
    "    for split, table in [\n",
    "        (\"train\", task.get_table(\"train\")),\n",
    "        (\"val\",task.get_table(\"val\")),\n",
    "        (\"test\", task.get_table(\"test\")),\n",
    "    ]:\n",
    "        table_input = get_node_train_table_input(\n",
    "            table=table,\n",
    "            task=task,\n",
    "        )\n",
    "        loader_dict[split] = NeighborLoader(\n",
    "            data,\n",
    "            num_neighbors=[\n",
    "                128 for i in range(2)\n",
    "            ],  # we sample subgraphs of depth 2, 128 neighbors per node.\n",
    "            time_attr=\"time\",\n",
    "            input_nodes=table_input.nodes,\n",
    "            input_time=table_input.time,\n",
    "            transform=table_input.transform,\n",
    "            batch_size=512,\n",
    "            temporal_strategy=\"uniform\",\n",
    "            shuffle=split == \"train\",\n",
    "            num_workers=0,\n",
    "            persistent_workers=False,\n",
    "        )\n",
    "    return loader_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from typing import List\n",
    "# def generate_loader_dict_specific_node(\n",
    "#     task: BaseTask, \n",
    "#     data:HeteroData, \n",
    "#     node_idxs: np.ndarray,\n",
    "#     num_neighbors: List[int] = [128, 64]\n",
    "# ):\n",
    "#     nodes = (task.entity_table, node_idxs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test(loader: NeighborLoader, model: torch.nn.Module, task: BaseTask, early_stop: int = 0)-> np.ndarray:\n",
    "    # model.eval()\n",
    "    pred_list = []\n",
    "    early_stop = early_stop if early_stop > 0 else len(loader)\n",
    "    for idx,batch in tqdm(enumerate(loader), leave=False, total=len(loader)):\n",
    "        if idx > early_stop:\n",
    "            break\n",
    "        batch = batch.to(device)\n",
    "        pred = model(\n",
    "            batch,\n",
    "            task.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "        pred_list.append(pred.detach().cpu())\n",
    "    return torch.cat(pred_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct bottom model\n",
    "channels = 128\n",
    "temporal_encoder = HeteroTemporalEncoder(\n",
    "    node_types=[\n",
    "                node_type for node_type in data.node_types if \"time\" in data[node_type]\n",
    "            ],\n",
    "    channels=channels,\n",
    ")\n",
    "\n",
    "feat_encoder = FeatureEncodingPart(\n",
    "    data=data,\n",
    "    node_to_col_stats=col_stats_dict,\n",
    "    channels=channels\n",
    ")\n",
    "\n",
    "node_encoder = NodeRepresentationPart(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    num_layers=1,\n",
    "    normalization=\"batch_norm\",\n",
    "    dropout_prob=0.2\n",
    ")\n",
    "\n",
    "\n",
    "net = CompositeModel(\n",
    "    data=data,\n",
    "    channels=channels,\n",
    "    out_channels=1,\n",
    "    dropout=0.2,\n",
    "    aggr=\"sum\",\n",
    "    norm=\"batch_norm\",\n",
    "    num_layer=2,\n",
    "    feature_encoder=feat_encoder,\n",
    "    node_encoder=node_encoder,\n",
    "    temporal_encoder=temporal_encoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for regression task, we need to deactivate the normalization and dropout layer\n",
    "task_a.task_type\n",
    "# freeze_instances = (torch.nn.BatchNorm1d, torch.nn.LayerNorm, torch.nn.Dropout, torch.nn.BatchNorm2d)\n",
    "deactive_nn_instances = (torch.nn.Dropout, torch.nn.Dropout2d, torch.nn.Dropout3d)\n",
    "net.train()\n",
    "for module in net.modules():\n",
    "    if isinstance(module, deactive_nn_instances):\n",
    "        module.eval()\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training for fine-tune\n",
    "from torch.nn import L1Loss\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, root_mean_squared_error\n",
    "\n",
    "task_loader_dict = generate_loader_dict(task_a,data)\n",
    "lr = 0.005\n",
    "epoches = 80\n",
    "loss_fn = L1Loss()\n",
    "tune_metric = \"mae\"\n",
    "higher_is_better = False\n",
    "early_stop = 10\n",
    "max_round_epoch = 30\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, net.parameters()), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Train loss: 0.2988541970650355, Val metrics: {'mae': 0.10188150754216693}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.10851538996354851}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02, Train loss: 0.11430266151825587, Val metrics: {'mae': 0.08766572650190438}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.09452000738041105}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03, Train loss: 0.1177882768213749, Val metrics: {'mae': 0.11989024395427574}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04, Train loss: 0.1299741397301356, Val metrics: {'mae': 0.10632366070429128}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05, Train loss: 0.11530769628783068, Val metrics: {'mae': 0.10124846532619582}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06, Train loss: 0.11626069297393163, Val metrics: {'mae': 0.08674288658178686}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.09373517212738722}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07, Train loss: 0.10260674630602201, Val metrics: {'mae': 0.07941188197968158}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.08654264810705653}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08, Train loss: 0.09734583447376886, Val metrics: {'mae': 0.07511450996646411}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.08223723034661459}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09, Train loss: 0.10251803075273831, Val metrics: {'mae': 0.08261271754949406}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Train loss: 0.09902743523319563, Val metrics: {'mae': 0.07114545625931808}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.07833163935449157}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Train loss: 0.09139947108924389, Val metrics: {'mae': 0.07084893097635359}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.07816547922287581}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, Train loss: 0.0909802682697773, Val metrics: {'mae': 0.06742855518884835}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.07496149396605438}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, Train loss: 0.09124470253785451, Val metrics: {'mae': 0.07076582333948132}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, Train loss: 0.0931877575814724, Val metrics: {'mae': 0.0664060892058307}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.0739216845628535}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Train loss: 0.08498411116500695, Val metrics: {'mae': 0.06957770751386323}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, Train loss: 0.09033782668411731, Val metrics: {'mae': 0.07011042113627614}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, Train loss: 0.08856107965111733, Val metrics: {'mae': 0.06577601294395886}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.07277351735647958}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, Train loss: 0.09163592060407003, Val metrics: {'mae': 0.06819643576758001}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Train loss: 0.08368172347545624, Val metrics: {'mae': 0.06804966834854842}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Train loss: 0.09337529217203458, Val metrics: {'mae': 0.0661360410688526}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, Train loss: 0.09264710880815982, Val metrics: {'mae': 0.06882739195319956}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, Train loss: 0.0876142393797636, Val metrics: {'mae': 0.0689975908023246}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Train loss: 0.08783800279100736, Val metrics: {'mae': 0.06732169781895994}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, Train loss: 0.09072480723261833, Val metrics: {'mae': 0.06848202060953947}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, Train loss: 0.09023997709155082, Val metrics: {'mae': 0.06631657025784579}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, Train loss: 0.08708882927894593, Val metrics: {'mae': 0.06537021931402634}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.07196546741219137}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Train loss: 0.0836745098233223, Val metrics: {'mae': 0.06537763979159696}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, Train loss: 0.08575024406115214, Val metrics: {'mae': 0.06593768214196305}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, Train loss: 0.09083325043320656, Val metrics: {'mae': 0.06658710503893862}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Train loss: 0.08647281800707181, Val metrics: {'mae': 0.06592833402001085}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31, Train loss: 0.08539213252564272, Val metrics: {'mae': 0.06591201357497423}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32, Train loss: 0.09393340547879538, Val metrics: {'mae': 0.06496944878047846}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.07136015656894468}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33, Train loss: 0.08622072227299213, Val metrics: {'mae': 0.06553802702662734}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Train loss: 0.08976320375998816, Val metrics: {'mae': 0.06515914596830757}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35, Train loss: 0.08273353974024454, Val metrics: {'mae': 0.06574916728823155}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36, Train loss: 0.091374629860123, Val metrics: {'mae': 0.0650337233879755}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37, Train loss: 0.08930601999163627, Val metrics: {'mae': 0.0664266195483958}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Train loss: 0.0837939412643512, Val metrics: {'mae': 0.06663893344340763}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39, Train loss: 0.08212159586449465, Val metrics: {'mae': 0.06482596127393751}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.07077645427100424}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40, Train loss: 0.0814968328922987, Val metrics: {'mae': 0.06490774026775291}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41, Train loss: 0.0856102659056584, Val metrics: {'mae': 0.06574970262720756}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42, Train loss: 0.08136231005191803, Val metrics: {'mae': 0.06474992035659473}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.07105183878931319}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43, Train loss: 0.08768302674094836, Val metrics: {'mae': 0.06444837342053791}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update the best scores\t Test metrics: {'mae': 0.07050292178730314}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44, Train loss: 0.09271791030963263, Val metrics: {'mae': 0.06545482316075286}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45, Train loss: 0.08501300079127153, Val metrics: {'mae': 0.0668853823842749}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46, Train loss: 0.087934560328722, Val metrics: {'mae': 0.0655809343845815}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47, Train loss: 0.08525236360728741, Val metrics: {'mae': 0.06588489615945027}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48, Train loss: 0.08644945832590262, Val metrics: {'mae': 0.06512880872575838}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49, Train loss: 0.08544362969696521, Val metrics: {'mae': 0.06525857923603486}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50, Train loss: 0.07839766989151636, Val metrics: {'mae': 0.06607129172938113}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51, Train loss: 0.09211349574228128, Val metrics: {'mae': 0.06731295384355351}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52, Train loss: 0.08585178442299365, Val metrics: {'mae': 0.06518343883887909}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53, Train loss: 0.08251386967798074, Val metrics: {'mae': 0.06658790314126388}\n",
      "Early stop at epoch 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = None\n",
    "best_val_metric = -math.inf if higher_is_better else math.inf\n",
    "net.to(device)\n",
    "best_epoch = 0\n",
    "patience = 0\n",
    "test_early_stop = 50\n",
    "# train\n",
    "for epoch in range(1, epoches + 1):\n",
    "    cnt = 0\n",
    "    loss_accum = count_accum = 0\n",
    "    # net.train()\n",
    "    for batch in tqdm(task_loader_dict[\"train\"], leave = False):\n",
    "        cnt += 1\n",
    "        if cnt > max_round_epoch:\n",
    "            break\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = net(\n",
    "            batch,\n",
    "            task_a.entity_table,\n",
    "        )\n",
    "        pred = pred.view(-1) if pred.size(1) == 1 else pred\n",
    "        loss = loss_fn(pred, batch[task_a.entity_table].y.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_accum += loss.detach().item() * pred.size(0)\n",
    "        count_accum += pred.size(0)\n",
    "\n",
    "    train_loss = loss_accum / count_accum\n",
    "\n",
    "    val_logits = test(task_loader_dict[\"val\"], net, task_a, test_early_stop)\n",
    "    val_logits = val_logits.numpy()\n",
    "    val_n = len(val_logits)\n",
    "    val_pred_hat = task_a.get_table(\"val\").df[task_a.target_col].to_numpy()[:val_n]\n",
    "    val_metrics = {\n",
    "        \"mae\": mean_absolute_error(val_pred_hat, val_logits),\n",
    "        # \"r2\": r2_score(val_pred_hat, val_logits),\n",
    "        # \"rmse\": root_mean_squared_error(val_pred_hat, val_logits),\n",
    "    }\n",
    "    print(f\"Epoch: {epoch:02d}, Train loss: {train_loss}, Val metrics: {val_metrics}\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    if (higher_is_better and val_metrics[tune_metric] > best_val_metric) or (\n",
    "        not higher_is_better and val_metrics[tune_metric] < best_val_metric\n",
    "    ):\n",
    "        patience = 0\n",
    "        best_epoch = epoch\n",
    "        best_val_metric = val_metrics[tune_metric]\n",
    "        state_dict = copy.deepcopy(net.state_dict())\n",
    "        # calculate test metrics\n",
    "        logits = test(task_loader_dict[\"test\"], net, task_a, test_early_stop)\n",
    "        logits = logits.numpy()\n",
    "        test_n = len(logits)\n",
    "        pred_hat = task_a.get_table(\"test\", mask_input_cols=False).df[task_a.target_col].to_numpy()[:test_n]\n",
    "        test_metrics = {\n",
    "                \"mae\": mean_absolute_error(pred_hat, logits),\n",
    "                # \"r2\": r2_score(pred_hat, logits),\n",
    "                # \"rmse\": root_mean_squared_error(pred_hat, logits),\n",
    "        }\n",
    "        print(f\"Update the best scores\\t Test metrics: {test_metrics}\")\n",
    "    else:\n",
    "        patience += 1\n",
    "    \n",
    "    if patience >= early_stop:\n",
    "        print(f\"Early stop at epoch {epoch}\")\n",
    "        break   \n",
    "    \n",
    "best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/315 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mae': 0.0642314010633084,\n",
       " 'r2': 0.232499361038208,\n",
       " 'rmse': 0.3233393236664935}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "net.load_state_dict(state_dict)\n",
    "logits = test(task_loader_dict[\"test\"], net, task_a)\n",
    "logits = logits.numpy()\n",
    "pred_hat = task_a.get_table(\"test\", mask_input_cols=False).df[task_a.target_col].to_numpy()\n",
    "test_metrics = {\n",
    "        \"mae\": mean_absolute_error(pred_hat, logits),\n",
    "        \"r2\": r2_score(pred_hat, logits),\n",
    "        \"rmse\": root_mean_squared_error(pred_hat, logits),\n",
    "}\n",
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
