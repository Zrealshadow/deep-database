{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from relbench.datasets import get_dataset\n",
    "from utils.data import preprocess_event_database\n",
    "from utils.data import StackDataset\n",
    "from tqdm import tqdm\n",
    "from torch_frame import stype\n",
    "import torch\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/stack/db...\n",
      "Done in 11.14 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = StackDataset(cache_dir=\"/home/lingze/.cache/relbench/stack\")\n",
    "db = dataset.get_db()\n",
    "cache_path = \"./data/stack-tensor-frame/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [NOTE]: the dataset has been materialized\n",
    "\n",
    "# get infer_type in cache\n",
    "type_path = os.path.join(cache_path,\"col_type_dict.pkl\")\n",
    "col_type_dict = pickle.load(open(type_path, \"rb\"))\n",
    "len(col_type_dict)\n",
    "\n",
    "# add \"compress_text\" in each table in case \n",
    "for table_name, table in db.table_dict.items():\n",
    "    table.df[\"text_compress\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tags': {'TagName': <stype.text_embedded: 'text_embedded'>,\n",
       "  'Id': <stype.categorical: 'categorical'>},\n",
       " 'postHistory': {'Id': <stype.categorical: 'categorical'>,\n",
       "  'PostId': <stype.categorical: 'categorical'>,\n",
       "  'UserId': <stype.categorical: 'categorical'>,\n",
       "  'PostHistoryTypeId': <stype.categorical: 'categorical'>,\n",
       "  'ContentLicense': <stype.categorical: 'categorical'>,\n",
       "  'RevisionGUID': <stype.categorical: 'categorical'>,\n",
       "  'CreationDate': <stype.timestamp: 'timestamp'>,\n",
       "  'text_compress': <stype.text_embedded: 'text_embedded'>},\n",
       " 'comments': {'Id': <stype.categorical: 'categorical'>,\n",
       "  'PostId': <stype.categorical: 'categorical'>,\n",
       "  'UserId': <stype.categorical: 'categorical'>,\n",
       "  'Score': <stype.categorical: 'categorical'>,\n",
       "  'ContentLicense': <stype.categorical: 'categorical'>,\n",
       "  'CreationDate': <stype.timestamp: 'timestamp'>,\n",
       "  'text_compress': <stype.text_embedded: 'text_embedded'>},\n",
       " 'badges': {'Id': <stype.categorical: 'categorical'>,\n",
       "  'UserId': <stype.categorical: 'categorical'>,\n",
       "  'Class': <stype.categorical: 'categorical'>,\n",
       "  'Name': <stype.text_embedded: 'text_embedded'>,\n",
       "  'TagBased': <stype.categorical: 'categorical'>,\n",
       "  'Date': <stype.timestamp: 'timestamp'>},\n",
       " 'postTag': {'Id': <stype.categorical: 'categorical'>,\n",
       "  'TagId': <stype.categorical: 'categorical'>,\n",
       "  'PostId': <stype.categorical: 'categorical'>},\n",
       " 'users': {'Id': <stype.categorical: 'categorical'>,\n",
       "  'AccountId': <stype.categorical: 'categorical'>,\n",
       "  'WebsiteUrl': <stype.categorical: 'categorical'>,\n",
       "  'CreationDate': <stype.timestamp: 'timestamp'>,\n",
       "  'text_compress': <stype.text_embedded: 'text_embedded'>},\n",
       " 'postLinks': {'Id': <stype.categorical: 'categorical'>,\n",
       "  'RelatedPostId': <stype.categorical: 'categorical'>,\n",
       "  'PostId': <stype.categorical: 'categorical'>,\n",
       "  'LinkTypeId': <stype.categorical: 'categorical'>,\n",
       "  'CreationDate': <stype.timestamp: 'timestamp'>},\n",
       " 'votes': {'Id': <stype.categorical: 'categorical'>,\n",
       "  'UserId': <stype.categorical: 'categorical'>,\n",
       "  'PostId': <stype.categorical: 'categorical'>,\n",
       "  'VoteTypeId': <stype.categorical: 'categorical'>,\n",
       "  'CreationDate': <stype.timestamp: 'timestamp'>},\n",
       " 'posts': {'Id': <stype.categorical: 'categorical'>,\n",
       "  'OwnerUserId': <stype.categorical: 'categorical'>,\n",
       "  'PostTypeId': <stype.categorical: 'categorical'>,\n",
       "  'AcceptedAnswerId': <stype.categorical: 'categorical'>,\n",
       "  'Score': <stype.numerical: 'numerical'>,\n",
       "  'ParentId': <stype.categorical: 'categorical'>,\n",
       "  'ContentLicense': <stype.categorical: 'categorical'>,\n",
       "  'Body': <stype.text_embedded: 'text_embedded'>,\n",
       "  'CreationDate': <stype.timestamp: 'timestamp'>,\n",
       "  'text_compress': <stype.text_embedded: 'text_embedded'>}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_type_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_num: 9, attr_num: 51, feat_num: 1062015, rel_num: 14, tuple_num: 4897438\n"
     ]
    }
   ],
   "source": [
    "table_num = 0\n",
    "attr_num = 0\n",
    "feat_num = 0\n",
    "rel_num = 0\n",
    "tuple_num = 0\n",
    "\n",
    "for table_name, col_types in col_type_dict.items():\n",
    "    table_num += 1\n",
    "    table = db.table_dict[table_name]\n",
    "    \n",
    "    tuple_num += len(table.df)\n",
    "    rel_num += len(table.fkey_col_to_pkey_table)\n",
    "    \n",
    "    for col_name, col_type in col_types.items():\n",
    "        attr_num += 1\n",
    "        \n",
    "        # if col_name is pkey or fkey\n",
    "        if col_name == table.pkey_col or col_name in table.fkey_col_to_pkey_table:\n",
    "            continue\n",
    "        \n",
    "        if col_type == stype.categorical:\n",
    "            feat_num += len(table.df[col_name].unique())\n",
    "        else:\n",
    "            feat_num += 1\n",
    "    \n",
    "print(f\"table_num: {table_num}, attr_num: {attr_num}, feat_num: {feat_num}, rel_num: {rel_num}, tuple_num: {tuple_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/rel-trial/db...\n",
      "Done in 8.76 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(name = \"rel-trial\", download = True)\n",
    "db = dataset.get_db()\n",
    "cache_path = \"data/rel-trial-tensor-frame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [NOTE]: the dataset has been materialized\n",
    "\n",
    "# get infer_type in cache\n",
    "type_path = os.path.join(cache_path,\"col_type_dict.pkl\")\n",
    "col_type_dict = pickle.load(open(type_path, \"rb\"))\n",
    "len(col_type_dict)\n",
    "\n",
    "# add \"compress_text\" in each table in case \n",
    "for table_name, table in db.table_dict.items():\n",
    "    table.df[\"text_compress\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_num: 15, attr_num: 77, feat_num: 5369, rel_num: 15, tuple_num: 5434924\n"
     ]
    }
   ],
   "source": [
    "table_num = 0\n",
    "attr_num = 0\n",
    "feat_num = 0\n",
    "rel_num = 0\n",
    "tuple_num = 0\n",
    "\n",
    "for table_name, col_types in col_type_dict.items():\n",
    "    table_num += 1\n",
    "    table = db.table_dict[table_name]\n",
    "    \n",
    "    tuple_num += len(table.df)\n",
    "    rel_num += len(table.fkey_col_to_pkey_table)\n",
    "    \n",
    "    for col_name, col_type in col_types.items():\n",
    "        attr_num += 1\n",
    "        \n",
    "        # if col_name is pkey or fkey\n",
    "        if col_name == table.pkey_col or col_name in table.fkey_col_to_pkey_table:\n",
    "            continue\n",
    "        \n",
    "        if col_type == stype.categorical:\n",
    "            feat_num += len(table.df[col_name].unique())\n",
    "        else:\n",
    "            feat_num += 1\n",
    "    \n",
    "print(f\"table_num: {table_num}, attr_num: {attr_num}, feat_num: {feat_num}, rel_num: {rel_num}, tuple_num: {tuple_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/rel-event/db...\n",
      "Done in 3.92 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lingze/embedding_fusion/utils/data.py:231: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  event_df[\"event_id\"].replace(event_id2index, inplace=True)\n",
      "/home/lingze/embedding_fusion/utils/data.py:231: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  event_df[\"event_id\"].replace(event_id2index, inplace=True)\n",
      "/home/lingze/embedding_fusion/utils/data.py:233: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  event_interest_df[\"event\"].replace(event_id2index, inplace=True)\n",
      "/home/lingze/embedding_fusion/utils/data.py:234: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  event_attendees_flattened_df[\"event\"].replace(event_id2index, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset('rel-event')\n",
    "db = dataset.get_db()\n",
    "preprocess_event_database(db)\n",
    "cache_path = \"./data/rel-event-tensor-frame/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [NOTE]: the dataset has been materialized\n",
    "\n",
    "# get infer_type in cache\n",
    "type_path = os.path.join(cache_path,\"col_type_dict.pkl\")\n",
    "col_type_dict = pickle.load(open(type_path, \"rb\"))\n",
    "len(col_type_dict)\n",
    "\n",
    "# add \"compress_text\" in each table in case \n",
    "for table_name, table in db.table_dict.items():\n",
    "    table.df[\"text_compress\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_num: 5, attr_num: 117, feat_num: 1651, rel_num: 7, tuple_num: 326268\n"
     ]
    }
   ],
   "source": [
    "table_num = 0\n",
    "attr_num = 0\n",
    "feat_num = 0\n",
    "rel_num = 0\n",
    "tuple_num = 0\n",
    "\n",
    "for table_name, col_types in col_type_dict.items():\n",
    "    table_num += 1\n",
    "    table = db.table_dict[table_name]\n",
    "    \n",
    "    tuple_num += len(table.df)\n",
    "    rel_num += len(table.fkey_col_to_pkey_table)\n",
    "    \n",
    "    for col_name, col_type in col_types.items():\n",
    "        attr_num += 1\n",
    "        \n",
    "        # if col_name is pkey or fkey\n",
    "        if col_name == table.pkey_col or col_name in table.fkey_col_to_pkey_table:\n",
    "            continue\n",
    "        \n",
    "        if col_type == stype.categorical:\n",
    "            feat_num += len(table.df[col_name].unique())\n",
    "        else:\n",
    "            feat_num += 1\n",
    "    \n",
    "print(f\"table_num: {table_num}, attr_num: {attr_num}, feat_num: {feat_num}, rel_num: {rel_num}, tuple_num: {tuple_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Database object from /home/lingze/.cache/relbench/rel-avito/db...\n",
      "Done in 4.65 seconds.\n"
     ]
    }
   ],
   "source": [
    "dataset = get_dataset(name = \"rel-avito\", download = True)\n",
    "db = dataset.get_db()\n",
    "cache_path = \"data/rel-avito-tensor-frame\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [NOTE]: the dataset has been materialized\n",
    "\n",
    "# get infer_type in cache\n",
    "type_path = os.path.join(cache_path,\"col_type_dict.pkl\")\n",
    "col_type_dict = pickle.load(open(type_path, \"rb\"))\n",
    "len(col_type_dict)\n",
    "\n",
    "# add \"compress_text\" in each table in case \n",
    "for table_name, table in db.table_dict.items():\n",
    "    table.df[\"text_compress\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table_num: 8, attr_num: 26, feat_num: 187162, rel_num: 11, tuple_num: 20679117\n"
     ]
    }
   ],
   "source": [
    "table_num = 0\n",
    "attr_num = 0\n",
    "feat_num = 0\n",
    "rel_num = 0\n",
    "tuple_num = 0\n",
    "\n",
    "for table_name, col_types in col_type_dict.items():\n",
    "    table_num += 1\n",
    "    table = db.table_dict[table_name]\n",
    "    \n",
    "    tuple_num += len(table.df)\n",
    "    rel_num += len(table.fkey_col_to_pkey_table)\n",
    "    \n",
    "    for col_name, col_type in col_types.items():\n",
    "        attr_num += 1\n",
    "        \n",
    "        # if col_name is pkey or fkey\n",
    "        if col_name == table.pkey_col or col_name in table.fkey_col_to_pkey_table:\n",
    "            continue\n",
    "        \n",
    "        if col_type == stype.categorical:\n",
    "            feat_num += len(table.df[col_name].unique())\n",
    "        else:\n",
    "            feat_num += 1\n",
    "    \n",
    "print(f\"table_num: {table_num}, attr_num: {attr_num}, feat_num: {feat_num}, rel_num: {rel_num}, tuple_num: {tuple_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
